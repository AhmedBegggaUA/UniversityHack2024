{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Fase Nacional del UniversityHack2024 ü§ñ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos las librer√≠as necesariasüóÇÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ahmedbegga/Desktop/Datathon_Fase_Nacional/entrega/script exploraci√≥n\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#¬†Imprimimos la ruta de trabajo\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creaci√≥n de los directorios üìÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#¬†Creamos los directorios de trabajo, sobre los que guardaremos los datos\n",
    "#¬†Carpeta processed_data y sus subcarpetas\n",
    "if not os.path.exists('./processed_data'):\n",
    "    os.makedirs('./processed_data')\n",
    "#¬†Carpeta biorreactores y centrifugadoras dentro de processed_data\n",
    "if not os.path.exists('./processed_data/biorreactores'):\n",
    "    os.makedirs('./processed_data/biorreactores')\n",
    "if not os.path.exists('./processed_data/centrifugadoras'):\n",
    "    os.makedirs('./processed_data/centrifugadoras')\n",
    "#¬†Carpeta train y test dentro de processed_data\n",
    "if not os.path.exists('./processed_data/train'):\n",
    "    os.makedirs('./processed_data/train')\n",
    "if not os.path.exists('./processed_data/test'):\n",
    "    os.makedirs('./processed_data/test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Procesamiento las OF \n",
    "\n",
    "\n",
    "Las ofs que seleccionemos son las que usaremos para el entrenamiento de nuestro modelo. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "of = pd.read_excel('data/OF 123456 v03.xlsx')\n",
    "# Eliminamos las columnas Unidad de medida, N√∫mero material y Texto breve material\n",
    "of = of.drop(columns=['Unidad de medida', 'N√∫mero material', 'Texto breve material','Orden'])\n",
    "#¬†Pasamos la columna Cantidad entregada a float\n",
    "of['Cantidad entregada'] = of['Cantidad entregada'].astype(float)\n",
    "#¬†SI hay alguna cantidad entregada igual o menor a 1, la cambiamos por la media de las cantidades entregadas\n",
    "mean = of['Cantidad entregada'].mean()\n",
    "of['Cantidad entregada'] = of['Cantidad entregada'].apply(lambda x: mean if x <= 1 else x)\n",
    "#¬†Eliminamos la fila que tiene un el valor Lote a P23273\n",
    "#of = of[of['Lote'] != 'P23273']\n",
    "#¬†Modificamos Lote para que deje de ser 23/019 y sea 23019 en formato int\n",
    "of['Lote'] = of['Lote'].apply(lambda x: str(x.replace('/', '')))\n",
    "of = of.rename(columns={'Cantidad entregada': 'CantidadEntregada'})\n",
    "#¬†Nos guardamos en un txt los lotes que hay en of\n",
    "lotes = of['Lote']\n",
    "with open('data/lotes.txt', 'w') as f:\n",
    "    for lote in lotes:\n",
    "        f.write(str(lote) + '\\n')\n",
    "of.to_csv('./processed_data/of.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¬†Procesamiento del Prein√≥culo üß´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de filas y columnas de preinoculo es:  (170, 12)\n",
      "El n√∫mero de filas y columnas de preinoculo es:  (169, 12)\n",
      "El n√∫mero de filas y columnas de preinoculo es:  (158, 12)\n",
      "El n√∫mero de filas y columnas de preinoculo es:  (157, 8)\n"
     ]
    }
   ],
   "source": [
    "preinoculo = pd.read_excel('./data/Fases producci√≥n v03.xlsx', sheet_name='Prein√≥culo')\n",
    "print(\"El n√∫mero de filas y columnas de preinoculo es: \", preinoculo.shape)\n",
    "#¬†Cambiamos el nombre de la columna Unnamed: 0 a Lote, Unnamed: 1 a F_h_init, Unnamed: 2 a F_h_end\n",
    "preinoculo = preinoculo.rename(columns={'Unnamed: 0': 'Lote', 'Unnamed: 1': 'F_h_init_prein', 'Unnamed: 2': 'F_h_end_prein'})\n",
    "#¬†Siguiendo con los cambios, cambiamos el nombre de la columna pH a pH_1, Unnamed: 4 a pH_2, Unnamed: 5 a pH_3\n",
    "preinoculo = preinoculo.rename(columns={'pH': 'pH_1', 'Unnamed: 4': 'pH_2', 'Unnamed: 5': 'pH_3'})\n",
    "#¬†Haremos lo mismo con la columna Turbidez que pasar√° a ser Turbidez_1, Unnamed: 7 a Turbidez_2, Unnamed: 8 a Turbidez_3\n",
    "preinoculo = preinoculo.rename(columns={'Turbidez': 'Turbidez_1', 'Unnamed: 7': 'Turbidez_2', 'Unnamed: 8': 'Turbidez_3'})\n",
    "#¬†Finalmente cambiaremos el nombre de la columna L√≠nea utilizada a Linea_utilizada_1, Unnamed: 10 a Linea_utilizada_2, Unnamed: 11 a Linea_utilizada_3\n",
    "preinoculo = preinoculo.rename(columns={'L√≠nea utilizada': 'Linea_utilizada_1', 'Unnamed: 10': 'Linea_utilizada_2', 'Unnamed: 11': 'Linea_utilizada_3'})\n",
    "#¬†Ahora nos cargamos la fila 0\n",
    "preinoculo = preinoculo.drop(0)\n",
    "#¬†Pasamos el lote a Int\n",
    "try:\n",
    "    preinoculo['Lote'] = preinoculo['Lote'].apply(lambda x: int(x))\n",
    "except:\n",
    "    #¬†Si no se puede pasar a int, es que hay un valor que no es un n√∫mero\n",
    "    # y por ende se tiene que eliminar\n",
    "    preinoculo = preinoculo[preinoculo['Lote'] != 'Lote']\n",
    "print(\"El n√∫mero de filas y columnas de preinoculo es: \", preinoculo.shape)\n",
    "#¬†OFs\n",
    "of = pd.read_csv('./processed_data/of.csv')\n",
    "#¬†Nos quedamos con el lote y lo pasamos a int\n",
    "of = of[['Lote']]\n",
    "of['Lote'] = of['Lote'].apply(lambda x: int(x))\n",
    "#¬†Solo usamos los lotes que est√°n en preinoculo\n",
    "preinoculo = preinoculo[preinoculo['Lote'].isin(of['Lote'])]\n",
    "print(\"El n√∫mero de filas y columnas de preinoculo es: \", preinoculo.shape)\n",
    "#¬†Comprobamos que la suma de las columnas l√≠nea 1, l√≠nea 2 y l√≠nea 3 es igual a 2\n",
    "#¬†En caso de que no, mostramos que filas no cumplen con la condici√≥n\n",
    "preinoculo['Linea_utilizada_1'] = preinoculo['Linea_utilizada_1'].astype(int)\n",
    "preinoculo['Linea_utilizada_2'] = preinoculo['Linea_utilizada_2'].astype(int)\n",
    "preinoculo['Linea_utilizada_3'] = preinoculo['Linea_utilizada_3'].astype(int)\n",
    "#¬†Creamos una nueva columna que se llame duracion_preinoculo que ser√° la resta de F_h_end_prein - F_h_init_prein\n",
    "preinoculo['F_h_init_prein'] = pd.to_datetime(preinoculo['F_h_init_prein'], format='%d.%m.%Y %H:%M:%S')\n",
    "preinoculo['F_h_end_prein'] = pd.to_datetime(preinoculo['F_h_end_prein'], format='%d.%m.%Y %H:%M:%S')\n",
    "#¬†A√±adimos una columna de duracion de la fase de preinoculo\n",
    "preinoculo['Duracion_preinoculo'] = preinoculo['F_h_end_prein'] - preinoculo['F_h_init_prein']\n",
    "#¬†Si dura m√°s de 10 dia, le restamos 10 d√≠a\n",
    "preinoculo['Duracion_preinoculo'] = preinoculo['Duracion_preinoculo'].apply(lambda x: x - pd.Timedelta(days=10) if x.days > 10 else x)\n",
    "#¬†SI hay alguna diracion negativa, la cambiamos a la media de las duraciones\n",
    "preinoculo['Duracion_preinoculo'] = preinoculo['Duracion_preinoculo'].apply(lambda x: x if x.total_seconds() > 0 else preinoculo['Duracion_preinoculo'].mean())\n",
    "#¬†Eliminamos las columnas F_h_init_prein y F_h_end_prein\n",
    "#preinoculo = preinoculo.drop(columns=['F_h_init_prein', 'F_h_end_prein'])\n",
    "\n",
    "#¬†Pasamos las columnas pH_1, pH_2 y pH_3 a float\n",
    "preinoculo['pH_1'] = pd.to_numeric(preinoculo['pH_1'], errors='coerce')\n",
    "preinoculo['pH_1'] = preinoculo['pH_1'].astype(float)\n",
    "preinoculo['pH_2'] = pd.to_numeric(preinoculo['pH_2'], errors='coerce')\n",
    "preinoculo['pH_2'] = preinoculo['pH_2'].astype(float)\n",
    "# En pH_3 hay un valor que no es un n√∫mero, lo cambiamos a NaN\n",
    "preinoculo['pH_3'] = pd.to_numeric(preinoculo['pH_3'], errors='coerce')\n",
    "preinoculo['pH_3'] = preinoculo['pH_3'].astype(float)\n",
    "#¬†Pasamos las columnas Turbidez_1, Turbidez_2 y Turbidez_3 a float\n",
    "preinoculo['Turbidez_1'] = preinoculo['Turbidez_1'].astype(float)\n",
    "preinoculo['Turbidez_2'] = preinoculo['Turbidez_2'].astype(float)\n",
    "# En Turbidez_3 hay un valor que no es un n√∫mero, lo cambiamos a NaN\n",
    "preinoculo['Turbidez_3'] = pd.to_numeric(preinoculo['Turbidez_3'], errors='coerce')\n",
    "preinoculo['Turbidez_3'] = preinoculo['Turbidez_3'].astype(float)\n",
    "\n",
    "# Para esas filas con nulos, lo que haremos ser√° rellenar los valores nulos con la media de los valores de la columna\n",
    "preinoculo['pH_1'] = preinoculo['pH_1'].fillna(preinoculo['pH_1'].mean())\n",
    "preinoculo['pH_2'] = preinoculo['pH_2'].fillna(preinoculo['pH_2'].mean())\n",
    "preinoculo['pH_3'] = preinoculo['pH_3'].fillna(preinoculo['pH_3'].mean())\n",
    "preinoculo['Turbidez_1'] = preinoculo['Turbidez_1'].fillna(preinoculo['Turbidez_1'].mean())\n",
    "preinoculo['Turbidez_2'] = preinoculo['Turbidez_2'].fillna(preinoculo['Turbidez_2'].mean())\n",
    "preinoculo['Turbidez_3'] = preinoculo['Turbidez_3'].fillna(preinoculo['Turbidez_3'].mean())\n",
    "preinoculo['Linea_utilizada_1'] = preinoculo['Linea_utilizada_1'].astype(int)\n",
    "preinoculo['Linea_utilizada_2'] = preinoculo['Linea_utilizada_2'].astype(int)\n",
    "preinoculo['Linea_utilizada_3'] = preinoculo['Linea_utilizada_3'].astype(int)\n",
    "# Ahora solo tendremos dos columnas de ph y turbidez, ya que solo imputaremos las mediciones cuyas lineas hayan sido utilizadas (que tengan un valor distinto de 0)\n",
    "# Creamos las columnas pH_1_utilizada, pH_2_utilizada, Turbidez_1_utilizada y Turbidez_2_utilizada\n",
    "preinoculo['pH_1_utilizada'] = 0\n",
    "preinoculo['pH_1_utilizada'] = preinoculo['pH_1_utilizada'].astype(float)\n",
    "preinoculo['pH_2_utilizada'] = 0 \n",
    "preinoculo['pH_2_utilizada'] = preinoculo['pH_2_utilizada'].astype(float)\n",
    "preinoculo['Turbidez_1_utilizada'] = 0\n",
    "preinoculo['Turbidez_1_utilizada'] = preinoculo['Turbidez_1_utilizada'].astype(float)\n",
    "preinoculo['Turbidez_2_utilizada'] = 0\n",
    "preinoculo['Turbidez_2_utilizada'] = preinoculo['Turbidez_2_utilizada'].astype(float)\n",
    "#¬†recorremos las filas\n",
    "for index, row in preinoculo.iterrows():\n",
    "    if row['Linea_utilizada_1'] != 0:\n",
    "        preinoculo.at[index, 'pH_1_utilizada'] = row['pH_1']\n",
    "        preinoculo.at[index, 'Turbidez_1_utilizada'] = row['Turbidez_1']\n",
    "    else:\n",
    "        preinoculo.at[index, 'pH_1_utilizada'] = row['pH_3']\n",
    "        preinoculo.at[index, 'Turbidez_1_utilizada'] = row['Turbidez_3']\n",
    "    if row['Linea_utilizada_2'] != 0:\n",
    "        preinoculo.at[index, 'pH_2_utilizada'] = row['pH_2']\n",
    "        preinoculo.at[index, 'Turbidez_2_utilizada'] = row['Turbidez_2']\n",
    "    else:\n",
    "        preinoculo.at[index, 'pH_2_utilizada'] = row['pH_3']\n",
    "        preinoculo.at[index, 'Turbidez_2_utilizada'] = row['Turbidez_3']\n",
    "#¬†Hacemos drop de las columnas que ya no necesitamos\n",
    "preinoculo = preinoculo.drop(columns=['pH_1', 'pH_2', 'pH_3', 'Turbidez_1', 'Turbidez_2', 'Turbidez_3'])\n",
    "preinoculo = preinoculo.drop(columns=['Linea_utilizada_1', 'Linea_utilizada_2', 'Linea_utilizada_3'])\n",
    "#¬†Nos guardamos el preinoculo\n",
    "# Antes de guardarlo, tenemos 2 lotes 24020, nos cargamos solo uno y dejamos el otro\n",
    "preinoculo = preinoculo.drop_duplicates(subset=['Lote'])\n",
    "print(\"El n√∫mero de filas y columnas de preinoculo es: \", preinoculo.shape)\n",
    "preinoculo.to_csv('./processed_data/preinoculo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¬†Procesamiento del in√≥culo üß™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de filas y columnas de inoculo es:  (168, 8)\n",
      "El n√∫mero de filas y columnas de inoculo es:  (168, 8)\n",
      "El n√∫mero de filas y columnas de inoculo es:  (157, 8)\n"
     ]
    }
   ],
   "source": [
    "inoculo = pd.read_excel('./data/Fases producci√≥n v03.xlsx', sheet_name='In√≥culo')\n",
    "inoculo = inoculo.rename(columns={'LOTE': 'Lote', 'ID bioreactor': 'ID_bioreactor', 'Fecha/hora inicio': 'F_h_init_in', 'Fecha/hora fin': 'F_h_end_in','Volumen de cultivo': 'Volumen_cultivo', 'Turbidez inicio cultivo': 'Turbidez_init', 'Turbidez final culttivo': 'Turbidez_end', 'Viabilidad final cultivo': 'Vialidad_end'})\n",
    "print(\"El n√∫mero de filas y columnas de inoculo es: \", inoculo.shape)\n",
    "try:\n",
    "    inoculo['Lote'] = inoculo['Lote'].apply(lambda x: int(x))\n",
    "except:\n",
    "    #¬†Si no se puede pasar a int, es que hay un valor que no es un n√∫mero\n",
    "    # y por ende se tiene que eliminar\n",
    "    inoculo = inoculo[inoculo['Lote'] != 'Lote']\n",
    "print(\"El n√∫mero de filas y columnas de inoculo es: \", inoculo.shape)\n",
    "#¬†OFs\n",
    "of = pd.read_csv('./processed_data/of.csv')\n",
    "#¬†Nos quedamos con el lote y lo pasamos a int\n",
    "of = of[['Lote']]\n",
    "of['Lote'] = of['Lote'].apply(lambda x: int(x))\n",
    "#¬†Solo usamos los lotes que est√°n en inoculo\n",
    "inoculo = inoculo[inoculo['Lote'].isin(of['Lote'])]\n",
    "inoculo = inoculo.drop_duplicates(subset=['Lote'])\n",
    "print(\"El n√∫mero de filas y columnas de inoculo es: \", inoculo.shape)\n",
    "# Pasamos la columna F_h_init_in y F_h_end_in a datetime\n",
    "inoculo['F_h_init_in'] = pd.to_datetime(inoculo['F_h_init_in'], format='%d.%m.%Y %H:%M:%S')\n",
    "inoculo['F_h_end_in'] = pd.to_datetime(inoculo['F_h_end_in'], format='%d.%m.%Y %H:%M:%S')\n",
    "#¬†A√±adimos una columna de duracion de la fase de in√≥culo\n",
    "inoculo['Duracion_inoculo'] = inoculo['F_h_end_in'] - inoculo['F_h_init_in']\n",
    "#¬†SI hay alguna diracion negativa, la cambiamos a la media de las duraciones\n",
    "inoculo['Duracion_inoculo'] = inoculo['Duracion_inoculo'].apply(lambda x: x if x.total_seconds() > 0 else inoculo['Duracion_inoculo'].mean())\n",
    "#¬†Pasamos la columna ID_bioreactor a int\n",
    "inoculo['ID_bioreactor'] = inoculo['ID_bioreactor'].astype(int)\n",
    "# Volumen_cultivo, Turbidez_init, Turbidez_end y Vialidad_end a float, pero antes, si tienen un NaN, lo cambiamos a pd.to_numeric\n",
    "inoculo['Volumen_cultivo'] = pd.to_numeric(inoculo['Volumen_cultivo'], errors='coerce')\n",
    "inoculo['Volumen_cultivo'] = inoculo['Volumen_cultivo'].astype(float)\n",
    "#¬†Si hay alg√∫n valor menor o igual a 0, lo cambiamos a la media de los valores\n",
    "mean = inoculo['Volumen_cultivo'].mean()\n",
    "inoculo['Volumen_cultivo'] = inoculo['Volumen_cultivo'].apply(lambda x: mean if x <= 0 else x)\n",
    "inoculo['Turbidez_init'] = pd.to_numeric(inoculo['Turbidez_init'], errors='coerce')\n",
    "inoculo['Turbidez_init'] = inoculo['Turbidez_init'].astype(float)\n",
    "mean = inoculo['Turbidez_init'].mean()\n",
    "inoculo['Turbidez_init'] = inoculo['Turbidez_init'].apply(lambda x: mean if x <= 0 else x)\n",
    "inoculo['Turbidez_end'] = pd.to_numeric(inoculo['Turbidez_end'], errors='coerce')\n",
    "inoculo['Turbidez_end'] = inoculo['Turbidez_end'].astype(float)\n",
    "mean = inoculo['Turbidez_end'].mean()\n",
    "inoculo['Turbidez_end'] = inoculo['Turbidez_end'].apply(lambda x: mean if x <= 0 else x)\n",
    "inoculo['Vialidad_end'] = pd.to_numeric(inoculo['Vialidad_end'], errors='coerce')\n",
    "inoculo['Vialidad_end'] = inoculo['Vialidad_end'].astype(float)\n",
    "mean = inoculo['Vialidad_end'].mean()\n",
    "inoculo['Vialidad_end'] = inoculo['Vialidad_end'].apply(lambda x: mean if x <= 0 else x)\n",
    "#¬†Nos guardamos el inoculo\n",
    "inoculo.to_csv('./processed_data/inoculo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¬†Procesamiento del cultivo üå±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de filas y columnas de cultivo es:  (161, 16)\n",
      "El n√∫mero de filas y columnas de cultivo es:  (161, 16)\n",
      "El n√∫mero de filas y columnas de cultivo es:  (150, 16)\n"
     ]
    }
   ],
   "source": [
    "cultivo = pd.read_excel('./data/Fases producci√≥n v03.xlsx', sheet_name='Cultivo final')\n",
    "cultivo = cultivo.rename(columns={'LOTE': 'Lote','Orden en el encadenado':'orden_encadenado', 'ID Bioreactor': 'ID_bioreactor', 'LOTE parental': 'Lote_parental', 'Fecha/hora inicio': 'F_h_init_cul', 'Fecha/hora fin': 'F_h_end_cul', 'Volumen de in√≥culo utilizado': 'Volumen_inoculo_used', 'Turbidez inicio cultivo': 'Turbidez_init_cul', 'Turbidez fin cultivo': 'Turbidez_end_cul', 'Viabilidad final cultivo': 'Vialidad_end_cul', 'ID Centr√≠fuga': 'ID_centrifuga', 'Centrifugaci√≥n 1 turbidez': 'Centrifugacion_1_turbidez', 'Centrifugaci√≥n 2 turbidez': 'Centrifugacion_2_turbidez'})\n",
    "#¬†Pasamos la columna F_h_init_cul y F_h_end_cul a datetime\n",
    "cultivo['F_h_init_cul'] = pd.to_datetime(cultivo['F_h_init_cul'], format='%d.%m.%Y %H:%M:%S')\n",
    "cultivo['F_h_end_cul'] = pd.to_datetime(cultivo['F_h_end_cul'], format='%d.%m.%Y %H:%M:%S')\n",
    "#¬†A√±adimos una columna de duracion de la fase de cultivo\n",
    "cultivo['Duracion_cultivo'] = cultivo['F_h_end_cul'] - cultivo['F_h_init_cul']\n",
    "print(\"El n√∫mero de filas y columnas de cultivo es: \", cultivo.shape)\n",
    "try:\n",
    "    cultivo['Lote'] = cultivo['Lote'].apply(lambda x: int(x))\n",
    "except:\n",
    "    #¬†Si no se puede pasar a int, es que hay un valor que no es un n√∫mero\n",
    "    # y por ende se tiene que eliminar\n",
    "    cultivo = cultivo[cultivo['Lote'] != 'Lote']\n",
    "print(\"El n√∫mero de filas y columnas de cultivo es: \", cultivo.shape)\n",
    "#¬†OFs\n",
    "of = pd.read_csv('./processed_data/of.csv')\n",
    "#¬†Nos quedamos con el lote y lo pasamos a int\n",
    "of = of[['Lote']]\n",
    "of['Lote'] = of['Lote'].apply(lambda x: int(x))\n",
    "#¬†Solo usamos los lotes que est√°n en cultivo\n",
    "cultivo = cultivo[cultivo['Lote'].isin(of['Lote'])]\n",
    "cultivo = cultivo.drop_duplicates(subset=['Lote'])\n",
    "print(\"El n√∫mero de filas y columnas de cultivo es: \", cultivo.shape)\n",
    "#¬†Pasamos la columna Volumen_inoculo_used a float\n",
    "cultivo['Volumen_inoculo_used'] = pd.to_numeric(cultivo['Volumen_inoculo_used'], errors='coerce')\n",
    "cultivo['Volumen_inoculo_used'] = cultivo['Volumen_inoculo_used'].astype(float)\n",
    "mean = cultivo['Volumen_inoculo_used'].mean()\n",
    "cultivo['Volumen_inoculo_used'] = cultivo['Volumen_inoculo_used'].apply(lambda x: mean if x <= 0 else x)\n",
    "#¬†Pasamos la columna Turbidez_init_cul y Turbidez_end_cul a float\n",
    "cultivo['Turbidez_init_cul'] = pd.to_numeric(cultivo['Turbidez_init_cul'], errors='coerce')\n",
    "cultivo['Turbidez_init_cul'] = cultivo['Turbidez_init_cul'].astype(float)\n",
    "mean = cultivo['Turbidez_init_cul'].mean()\n",
    "cultivo['Turbidez_init_cul'] = cultivo['Turbidez_init_cul'].apply(lambda x: mean if x <= 0 else x)\n",
    "cultivo['Turbidez_end_cul'] = pd.to_numeric(cultivo['Turbidez_end_cul'], errors='coerce')\n",
    "cultivo['Turbidez_end_cul'] = cultivo['Turbidez_end_cul'].astype(float)\n",
    "mean = cultivo['Turbidez_end_cul'].mean()\n",
    "cultivo['Turbidez_end_cul'] = cultivo['Turbidez_end_cul'].apply(lambda x: mean if x <= 0 else x)\n",
    "#¬†Pasamos la columna Vialidad_end_cul a float\n",
    "cultivo['Vialidad_end_cul'] = pd.to_numeric(cultivo['Vialidad_end_cul'], errors='coerce')\n",
    "cultivo['Vialidad_end_cul'] = cultivo['Vialidad_end_cul'].astype(float)\n",
    "mean = cultivo['Vialidad_end_cul'].mean()\n",
    "cultivo['Vialidad_end_cul'] = cultivo['Vialidad_end_cul'].apply(lambda x: mean if x <= 0 else x)\n",
    "#¬†Pasamos la columna ID_centrifuga a int\n",
    "cultivo['ID_centrifuga'] = cultivo['ID_centrifuga'].astype(int)\n",
    "#¬†Pasamos la columna Centrifugacion_1_turbidez y Centrifugacion_2_turbidez a float\n",
    "cultivo['Centrifugacion_1_turbidez'] = pd.to_numeric(cultivo['Centrifugacion_1_turbidez'], errors='coerce')\n",
    "cultivo['Centrifugacion_1_turbidez'] = cultivo['Centrifugacion_1_turbidez'].astype(float)\n",
    "mean = cultivo['Centrifugacion_1_turbidez'].mean()\n",
    "cultivo['Centrifugacion_1_turbidez'] = cultivo['Centrifugacion_1_turbidez'].apply(lambda x: mean if x <= 0 else x)\n",
    "cultivo['Centrifugacion_2_turbidez'] = pd.to_numeric(cultivo['Centrifugacion_2_turbidez'], errors='coerce')\n",
    "cultivo['Centrifugacion_2_turbidez'] = cultivo['Centrifugacion_2_turbidez'].astype(float)\n",
    "mean = cultivo['Centrifugacion_2_turbidez'].mean()\n",
    "cultivo['Centrifugacion_2_turbidez'] = cultivo['Centrifugacion_2_turbidez'].apply(lambda x: mean if x <= 0 else x)\n",
    "#¬†Pasamos la columna Producto 1 a Float\n",
    "cultivo['Producto 1'] = pd.to_numeric(cultivo['Producto 1'], errors='coerce')\n",
    "cultivo['Producto 1'] = cultivo['Producto 1'].astype(float)\n",
    "mean = cultivo['Producto 1'].mean()\n",
    "cultivo['Producto 1'] = cultivo['Producto 1'].apply(lambda x: mean if x <= 0 else x)\n",
    "#¬†Nos guardamos el cultivo\n",
    "cultivo.to_csv('./processed_data/cultivo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de filas y columnas de cultivo es:  (55, 16)\n",
      "El n√∫mero de filas y columnas de cultivo es:  (55, 16)\n",
      "El n√∫mero de filas y columnas de cultivo es:  (55, 16)\n"
     ]
    }
   ],
   "source": [
    "cultivo = pd.read_excel('./data/Fases producci√≥n v03 Test.xlsx', sheet_name='Cultivo final')\n",
    "cultivo = cultivo.rename(columns={'LOTE': 'Lote','Orden en el encadenado':'orden_encadenado', 'ID Bioreactor': 'ID_bioreactor', 'LOTE parental': 'Lote_parental', 'Fecha/hora inicio': 'F_h_init_cul', 'Fecha/hora fin': 'F_h_end_cul', 'Volumen de in√≥culo utilizado': 'Volumen_inoculo_used', 'Turbidez inicio cultivo': 'Turbidez_init_cul', 'Turbidez fin cultivo': 'Turbidez_end_cul', 'Viabilidad final cultivo': 'Vialidad_end_cul', 'ID Centr√≠fuga': 'ID_centrifuga', 'Centrifugaci√≥n 1 turbidez': 'Centrifugacion_1_turbidez', 'Centrifugaci√≥n 2 turbidez': 'Centrifugacion_2_turbidez'})\n",
    "#¬†Pasamos la columna F_h_init_cul y F_h_end_cul a datetime\n",
    "cultivo['F_h_init_cul'] = pd.to_datetime(cultivo['F_h_init_cul'], format='%d.%m.%Y %H:%M:%S')\n",
    "cultivo['F_h_end_cul'] = pd.to_datetime(cultivo['F_h_end_cul'], format='%d.%m.%Y %H:%M:%S')\n",
    "#¬†A√±adimos una columna de duracion de la fase de cultivo\n",
    "cultivo['Duracion_cultivo'] = cultivo['F_h_end_cul'] - cultivo['F_h_init_cul']\n",
    "print(\"El n√∫mero de filas y columnas de cultivo es: \", cultivo.shape)\n",
    "try:\n",
    "    cultivo['Lote'] = cultivo['Lote'].apply(lambda x: int(x))\n",
    "except:\n",
    "    #¬†Si no se puede pasar a int, es que hay un valor que no es un n√∫mero\n",
    "    # y por ende se tiene que eliminar\n",
    "    cultivo = cultivo[cultivo['Lote'] != 'Lote']\n",
    "print(\"El n√∫mero de filas y columnas de cultivo es: \", cultivo.shape)\n",
    "#¬†OFs\n",
    "of = pd.read_csv('./processed_data/of.csv')\n",
    "#¬†Nos quedamos con el lote y lo pasamos a int\n",
    "of = of[['Lote']]\n",
    "of['Lote'] = of['Lote'].apply(lambda x: int(x))\n",
    "#¬†Solo usamos los lotes que est√°n en cultivo\n",
    "cultivo = cultivo[cultivo['Lote'].isin(of['Lote'])]\n",
    "cultivo = cultivo.drop_duplicates(subset=['Lote'])\n",
    "print(\"El n√∫mero de filas y columnas de cultivo es: \", cultivo.shape)\n",
    "#¬†Pasamos la columna Volumen_inoculo_used a float\n",
    "cultivo['Volumen_inoculo_used'] = pd.to_numeric(cultivo['Volumen_inoculo_used'], errors='coerce')\n",
    "cultivo['Volumen_inoculo_used'] = cultivo['Volumen_inoculo_used'].astype(float)\n",
    "mean = cultivo['Volumen_inoculo_used'].mean()\n",
    "cultivo['Volumen_inoculo_used'] = cultivo['Volumen_inoculo_used'].apply(lambda x: mean if x <= 0 else x)\n",
    "#¬†Pasamos la columna Turbidez_init_cul y Turbidez_end_cul a float\n",
    "cultivo['Turbidez_init_cul'] = pd.to_numeric(cultivo['Turbidez_init_cul'], errors='coerce')\n",
    "cultivo['Turbidez_init_cul'] = cultivo['Turbidez_init_cul'].astype(float)\n",
    "mean = cultivo['Turbidez_init_cul'].mean()\n",
    "cultivo['Turbidez_init_cul'] = cultivo['Turbidez_init_cul'].apply(lambda x: mean if x <= 0 else x)\n",
    "cultivo['Turbidez_end_cul'] = pd.to_numeric(cultivo['Turbidez_end_cul'], errors='coerce')\n",
    "cultivo['Turbidez_end_cul'] = cultivo['Turbidez_end_cul'].astype(float)\n",
    "mean = cultivo['Turbidez_end_cul'].mean()\n",
    "cultivo['Turbidez_end_cul'] = cultivo['Turbidez_end_cul'].apply(lambda x: mean if x <= 0 else x)\n",
    "#¬†Pasamos la columna Vialidad_end_cul a float\n",
    "cultivo['Vialidad_end_cul'] = pd.to_numeric(cultivo['Vialidad_end_cul'], errors='coerce')\n",
    "cultivo['Vialidad_end_cul'] = cultivo['Vialidad_end_cul'].astype(float)\n",
    "mean = cultivo['Vialidad_end_cul'].mean()\n",
    "cultivo['Vialidad_end_cul'] = cultivo['Vialidad_end_cul'].apply(lambda x: mean if x <= 0 else x)\n",
    "#¬†Pasamos la columna ID_centrifuga a int\n",
    "cultivo['ID_centrifuga'] = cultivo['ID_centrifuga'].astype(int)\n",
    "#¬†Pasamos la columna Centrifugacion_1_turbidez y Centrifugacion_2_turbidez a float\n",
    "cultivo['Centrifugacion_1_turbidez'] = pd.to_numeric(cultivo['Centrifugacion_1_turbidez'], errors='coerce')\n",
    "cultivo['Centrifugacion_1_turbidez'] = cultivo['Centrifugacion_1_turbidez'].astype(float)\n",
    "mean = cultivo['Centrifugacion_1_turbidez'].mean()\n",
    "cultivo['Centrifugacion_1_turbidez'] = cultivo['Centrifugacion_1_turbidez'].apply(lambda x: mean if x <= 0 else x)\n",
    "cultivo['Centrifugacion_2_turbidez'] = pd.to_numeric(cultivo['Centrifugacion_2_turbidez'], errors='coerce')\n",
    "cultivo['Centrifugacion_2_turbidez'] = cultivo['Centrifugacion_2_turbidez'].astype(float)\n",
    "mean = cultivo['Centrifugacion_2_turbidez'].mean()\n",
    "cultivo['Centrifugacion_2_turbidez'] = cultivo['Centrifugacion_2_turbidez'].apply(lambda x: mean if x <= 0 else x)\n",
    "#¬†Nos guardamos el cultivo\n",
    "cultivo.to_csv('./processed_data/cultivo_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamos los Cin√©ticos üìà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de filas y columnas de cineticos_inoculos es:  (737, 4)\n",
      "El n√∫mero de filas y columnas de cineticos_inoculos es:  (737, 4)\n",
      "El n√∫mero de filas y columnas de cineticos_inoculos es:  (654, 4)\n",
      "El n√∫mero de filas y columnas de cineticos_inoculos es:  (157, 7)\n"
     ]
    }
   ],
   "source": [
    "#¬†Ahora leemos CineÃÅticos IPC.xlsx, pero solo la p√°gina de In√≥culos\n",
    "cineticos_inoculos = pd.read_excel('data/CineÃÅticos IPC.xlsx', sheet_name='In√≥culos')\n",
    "print(\"El n√∫mero de filas y columnas de cineticos_inoculos es: \", cineticos_inoculos.shape)\n",
    "try:\n",
    "    cineticos_inoculos['Lote'] = cineticos_inoculos['Lote'].apply(lambda x: int(x))\n",
    "except:\n",
    "    #¬†Si no se puede pasar a int, es que hay un valor que no es un n√∫mero\n",
    "    # y por ende se tiene que eliminar\n",
    "    cineticos_inoculos = cineticos_inoculos[cineticos_inoculos['Lote'] != 'Lote']\n",
    "print(\"El n√∫mero de filas y columnas de cineticos_inoculos es: \", cineticos_inoculos.shape)\n",
    "#¬†OFs\n",
    "of = pd.read_csv('./processed_data/of.csv')\n",
    "#¬†Nos quedamos con el lote y lo pasamos a int\n",
    "of = of[['Lote']]\n",
    "of['Lote'] = of['Lote'].apply(lambda x: int(x))\n",
    "#¬†Solo usamos los lotes que est√°n en cineticos_inoculos\n",
    "cineticos_inoculos = cineticos_inoculos[cineticos_inoculos['Lote'].isin(of['Lote'])]\n",
    "print(\"El n√∫mero de filas y columnas de cineticos_inoculos es: \", cineticos_inoculos.shape)\n",
    "# Pasamos la columna Fecha de inicio a datetime con horas y minutos\n",
    "cineticos_inoculos['Fecha'] = pd.to_datetime(cineticos_inoculos['Fecha'], format='%d.%m.%Y %H:%M:%S')\n",
    "#¬†Cambiamos el nombre de Fecha a F_h_cin_in\n",
    "cineticos_inoculos = cineticos_inoculos.rename(columns={'Fecha': 'F_h_cin_cul'})\n",
    "#¬†Pasamos las columnas Turbidez, Viabilidad y Glucosa g/L a float\n",
    "cineticos_inoculos['Turbidez'] = pd.to_numeric(cineticos_inoculos['Turbidez'], errors='coerce')\n",
    "cineticos_inoculos['Turbidez'] = cineticos_inoculos['Turbidez'].astype(float)\n",
    "#¬†Si hay alg√∫n valor NaN en Turbidez o Viabilidad, lo cambiamos usando forward fill\n",
    "cineticos_inoculos['Turbidez'] = cineticos_inoculos['Turbidez'].fillna(method='ffill')\n",
    "cineticos_inoculos['Viabilidad'] = pd.to_numeric(cineticos_inoculos['Viabilidad'], errors='coerce')\n",
    "cineticos_inoculos['Viabilidad'] = cineticos_inoculos['Viabilidad'].astype(float)\n",
    "cineticos_inoculos['Viabilidad'] = cineticos_inoculos['Viabilidad'].fillna(method='ffill')\n",
    "# Para cada lote sacamos la media de la turbidez y la viabilidad\n",
    "lotes = cineticos_inoculos['Lote'].unique()\n",
    "turbideces_min = []\n",
    "turbideces_mean = []\n",
    "turbideces_max = []\n",
    "viabilidades_min = []\n",
    "viabilidades_mean = []\n",
    "viabilidades_max = []\n",
    "for lote in lotes:\n",
    "    cinetico = cineticos_inoculos[cineticos_inoculos['Lote'] == lote]\n",
    "    turbideces_min.append(cinetico['Turbidez'].min())\n",
    "    turbideces_mean.append(cinetico['Turbidez'].mean())\n",
    "    turbideces_max.append(cinetico['Turbidez'].max())\n",
    "    viabilidades_min.append(cinetico['Viabilidad'].min())\n",
    "    viabilidades_mean.append(cinetico['Viabilidad'].mean())\n",
    "    viabilidades_max.append(cinetico['Viabilidad'].max())\n",
    "#¬†Creamos un dataframe con los valores\n",
    "cineticos_inoculos = pd.DataFrame({'Lote': lotes, 'Turbidez_min': turbideces_min, 'Turbidez_mean': turbideces_mean, 'Turbidez_max': turbideces_max, 'Viabilidad_min': viabilidades_min, 'Viabilidad_mean': viabilidades_mean, 'Viabilidad_max': viabilidades_max})\n",
    "print(\"El n√∫mero de filas y columnas de cineticos_inoculos es: \", cineticos_inoculos.shape)\n",
    "#¬†Nos guardamos el cineticos_inoculos\n",
    "cineticos_inoculos.to_csv('./processed_data/cineticos_inoculos.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¬†Procesamiento de m√°s cin√©ticos üìà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de filas y columnas de cineticos_cultivos es:  (1911, 5)\n",
      "El n√∫mero de filas y columnas de cineticos_cultivos es:  (1911, 5)\n",
      "El n√∫mero de filas y columnas de cineticos_cultivos es:  (1710, 5)\n",
      "El n√∫mero de filas y columnas de cineticos_cultivos es:  (204, 10)\n"
     ]
    }
   ],
   "source": [
    "cineticos_cultivos = pd.read_excel('data/CineÃÅticos IPC.xlsx', sheet_name='Cultivos finales')\n",
    "print(\"El n√∫mero de filas y columnas de cineticos_cultivos es: \", cineticos_cultivos.shape)\n",
    "try:\n",
    "    cineticos_cultivos['Lote'] = cineticos_cultivos['Lote'].apply(lambda x: int(x))\n",
    "except:\n",
    "    #¬†Si no se puede pasar a int, es que hay un valor que no es un n√∫mero\n",
    "    # y por ende se tiene que eliminar\n",
    "    cineticos_cultivos = cineticos_cultivos[cineticos_cultivos['Lote'] != 'Lote']\n",
    "print(\"El n√∫mero de filas y columnas de cineticos_cultivos es: \", cineticos_cultivos.shape)\n",
    "#¬†OFs\n",
    "of = pd.read_csv('./processed_data/of.csv')\n",
    "#¬†Nos quedamos con el lote y lo pasamos a int\n",
    "of = of[['Lote']]\n",
    "of['Lote'] = of['Lote'].apply(lambda x: int(x))\n",
    "#¬†Solo usamos los lotes que est√°n en cineticos_cultivos\n",
    "cineticos_cultivos = cineticos_cultivos[cineticos_cultivos['Lote'].isin(of['Lote'])]\n",
    "print(\"El n√∫mero de filas y columnas de cineticos_cultivos es: \", cineticos_cultivos.shape)\n",
    "\n",
    "# Pasamos la columna Fecha de inicio a datetime con horas y minutos\n",
    "cineticos_cultivos['Fecha'] = pd.to_datetime(cineticos_cultivos['Fecha'], format='%d.%m.%Y %H:%M:%S')\n",
    "#¬†Cambiamos el nombre de Fecha a F_h_cin_in\n",
    "cineticos_cultivos = cineticos_cultivos.rename(columns={'Fecha': 'F_h_cin_cul'})\n",
    "#¬†Pasamos las columnas Turbidez, Viabilidad y Glucosa g/L a float\n",
    "cineticos_cultivos['Turbidez'] = pd.to_numeric(cineticos_cultivos['Turbidez'], errors='coerce')\n",
    "cineticos_cultivos['Turbidez'] = cineticos_cultivos['Turbidez'].astype(float)\n",
    "#¬†Si hay alg√∫n valor NaN en Turbidez o Viabilidad, lo cambiamos usando forward fill\n",
    "cineticos_cultivos['Turbidez'] = cineticos_cultivos['Turbidez'].fillna(method='ffill')\n",
    "cineticos_cultivos['Viabilidad'] = pd.to_numeric(cineticos_cultivos['Viabilidad'], errors='coerce')\n",
    "cineticos_cultivos['Viabilidad'] = cineticos_cultivos['Viabilidad'].astype(float)\n",
    "cineticos_cultivos['Viabilidad'] = cineticos_cultivos['Viabilidad'].fillna(method='ffill')\n",
    "cineticos_cultivos['Glucosa g/L'] = pd.to_numeric(cineticos_cultivos['Glucosa g/L'], errors='coerce')\n",
    "cineticos_cultivos['Glucosa g/L'] = cineticos_cultivos['Glucosa g/L'].astype(float)\n",
    "cineticos_cultivos['Glucosa g/L'] = cineticos_cultivos['Glucosa g/L'].fillna(method='ffill')\n",
    "# Para cada lote sacamos el minimo, la media y el maximo de la turbidez, la viabilidad y la glucosa\n",
    "lotes = cineticos_cultivos['Lote'].unique()\n",
    "turbideces_min = []\n",
    "turbideces_mean = []\n",
    "turbideces_max = []\n",
    "viabilidades_min = []\n",
    "viabilidades_mean = []\n",
    "viabilidades_max = []\n",
    "glucosas_min = []\n",
    "glucosas_mean = []\n",
    "glucosas_max = []\n",
    "for lote in lotes:\n",
    "    cinetico = cineticos_cultivos[cineticos_cultivos['Lote'] == lote]\n",
    "    turbideces_min.append(cinetico['Turbidez'].min())\n",
    "    turbideces_mean.append(cinetico['Turbidez'].mean())\n",
    "    turbideces_max.append(cinetico['Turbidez'].max())\n",
    "    viabilidades_min.append(cinetico['Viabilidad'].min())\n",
    "    viabilidades_mean.append(cinetico['Viabilidad'].mean())\n",
    "    viabilidades_max.append(cinetico['Viabilidad'].max())\n",
    "    glucosas_min.append(cinetico['Glucosa g/L'].min())\n",
    "    glucosas_mean.append(cinetico['Glucosa g/L'].mean())\n",
    "    glucosas_max.append(cinetico['Glucosa g/L'].max())\n",
    "#¬†Creamos un dataframe con los valores\n",
    "cineticos_cultivos = pd.DataFrame({'Lote': lotes, 'Turbidez_min': turbideces_min, 'Turbidez_mean': turbideces_mean, 'Turbidez_max': turbideces_max, 'Viabilidad_min': viabilidades_min, 'Viabilidad_mean': viabilidades_mean, 'Viabilidad_max': viabilidades_max, 'Glucosa_min': glucosas_min, 'Glucosa_mean': glucosas_mean, 'Glucosa_max': glucosas_max})\n",
    "cineticos_cultivos = cineticos_cultivos.drop_duplicates(subset=['Lote'])\n",
    "print(\"El n√∫mero de filas y columnas de cineticos_cultivos es: \", cineticos_cultivos.shape)\n",
    "#¬†Nos guardamos el cineticos_cultivos\n",
    "cineticos_cultivos.to_csv('./processed_data/cineticos_cultivos.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¬†Procesamiento de m√°s cin√©ticos üìà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de filas y columnas de cineticos_centrifugacion es:  (2426, 5)\n",
      "El n√∫mero de filas y columnas de cineticos_centrifugacion es:  (2426, 5)\n",
      "El n√∫mero de filas y columnas de cineticos_centrifugacion es:  (2195, 5)\n",
      "El n√∫mero de filas y columnas de cineticos_centrifugacion es:  (205, 13)\n"
     ]
    }
   ],
   "source": [
    "cineticos_centrifugacion = pd.read_excel('data/CineÃÅticos IPC.xlsx', sheet_name='Centrifugaci√≥n')\n",
    "print(\"El n√∫mero de filas y columnas de cineticos_centrifugacion es: \", cineticos_centrifugacion.shape)\n",
    "try:\n",
    "    cineticos_centrifugacion['Lote'] = cineticos_centrifugacion['Lote'].apply(lambda x: int(x))\n",
    "except:\n",
    "    #¬†Si no se puede pasar a int, es que hay un valor que no es un n√∫mero\n",
    "    # y por ende se tiene que eliminar\n",
    "    cineticos_centrifugacion = cineticos_centrifugacion[cineticos_centrifugacion['Lote'] != 'Lote']\n",
    "print(\"El n√∫mero de filas y columnas de cineticos_centrifugacion es: \", cineticos_centrifugacion.shape)\n",
    "#¬†OFs\n",
    "of = pd.read_csv('./processed_data/of.csv')\n",
    "#¬†Nos quedamos con el lote y lo pasamos a int\n",
    "of = of[['Lote']]\n",
    "of['Lote'] = of['Lote'].apply(lambda x: int(x))\n",
    "#¬†Solo usamos los lotes que est√°n en cineticos_centrifugacion\n",
    "cineticos_centrifugacion = cineticos_centrifugacion[cineticos_centrifugacion['Lote'].isin(of['Lote'])]\n",
    "print(\"El n√∫mero de filas y columnas de cineticos_centrifugacion es: \", cineticos_centrifugacion.shape)\n",
    "#¬†La columna Centrifugada (1 o 2) la vamos a eliminar, para crear Volumen_centrifugado_1 y Volumen_centrifugado_2 y Turbidez_centrifugado_1 y Turbidez_centrifugado_2\n",
    "vol_centrifugado_1 = []\n",
    "vol_centrifugado_2 = []\n",
    "turbidez_centrifugado_1 = []\n",
    "turbidez_centrifugado_2 = []\n",
    "for index, row in cineticos_centrifugacion.iterrows():\n",
    "    if row['Centrifugada (1 o 2)'] == 1:\n",
    "        vol_centrifugado_1.append(row['Volumen centrifugado (L)'])\n",
    "        turbidez_centrifugado_1.append(row['Turbidez'])\n",
    "        vol_centrifugado_2.append(0)\n",
    "        turbidez_centrifugado_2.append(0)\n",
    "    else:\n",
    "        vol_centrifugado_2.append(row['Volumen centrifugado (L)'])\n",
    "        turbidez_centrifugado_2.append(row['Turbidez'])\n",
    "        vol_centrifugado_1.append(0)\n",
    "        turbidez_centrifugado_1.append(0)\n",
    "cineticos_centrifugacion = cineticos_centrifugacion.drop(columns=['Centrifugada (1 o 2)', 'Volumen centrifugado (L)', 'Turbidez'])\n",
    "cineticos_centrifugacion['Volumen_centrifugado_1'] = vol_centrifugado_1\n",
    "cineticos_centrifugacion['Volumen_centrifugado_2'] = vol_centrifugado_2\n",
    "cineticos_centrifugacion['Turbidez_centrifugado_1'] = turbidez_centrifugado_1\n",
    "cineticos_centrifugacion['Turbidez_centrifugado_2'] = turbidez_centrifugado_2\n",
    "#¬†Pasamos las columnas nuevas a float\n",
    "cineticos_centrifugacion['Volumen_centrifugado_1'] = pd.to_numeric(cineticos_centrifugacion['Volumen_centrifugado_1'], errors='coerce')\n",
    "cineticos_centrifugacion['Volumen_centrifugado_1'] = cineticos_centrifugacion['Volumen_centrifugado_1'].astype(float)\n",
    "cineticos_centrifugacion['Volumen_centrifugado_1'] = cineticos_centrifugacion['Volumen_centrifugado_1'].fillna(method='ffill')\n",
    "cineticos_centrifugacion['Volumen_centrifugado_2'] = pd.to_numeric(cineticos_centrifugacion['Volumen_centrifugado_2'], errors='coerce')\n",
    "cineticos_centrifugacion['Volumen_centrifugado_2'] = cineticos_centrifugacion['Volumen_centrifugado_2'].astype(float)\n",
    "cineticos_centrifugacion['Volumen_centrifugado_2'] = cineticos_centrifugacion['Volumen_centrifugado_2'].fillna(method='ffill')\n",
    "cineticos_centrifugacion['Turbidez_centrifugado_1'] = pd.to_numeric(cineticos_centrifugacion['Turbidez_centrifugado_1'], errors='coerce')\n",
    "cineticos_centrifugacion['Turbidez_centrifugado_1'] = cineticos_centrifugacion['Turbidez_centrifugado_1'].astype(float)\n",
    "cineticos_centrifugacion['Turbidez_centrifugado_1'] = cineticos_centrifugacion['Turbidez_centrifugado_1'].fillna(method='ffill')\n",
    "cineticos_centrifugacion['Turbidez_centrifugado_2'] = pd.to_numeric(cineticos_centrifugacion['Turbidez_centrifugado_2'], errors='coerce')\n",
    "cineticos_centrifugacion['Turbidez_centrifugado_2'] = cineticos_centrifugacion['Turbidez_centrifugado_2'].astype(float)\n",
    "cineticos_centrifugacion['Turbidez_centrifugado_2'] = cineticos_centrifugacion['Turbidez_centrifugado_2'].fillna(method='ffill')\n",
    "#¬†Ahora sacamos el minimum, mean y maximum de los valores de turbidez y volumen de cada lote\n",
    "lotes = cineticos_centrifugacion['Lote'].unique()\n",
    "vol_centrifugado_1_min = []\n",
    "vol_centrifugado_1_mean = []\n",
    "vol_centrifugado_1_max = []\n",
    "vol_centrifugado_2_min = []\n",
    "vol_centrifugado_2_mean = []\n",
    "vol_centrifugado_2_max = []\n",
    "turbidez_centrifugado_1_min = []\n",
    "turbidez_centrifugado_1_mean = []\n",
    "turbidez_centrifugado_1_max = []\n",
    "turbidez_centrifugado_2_min = []\n",
    "turbidez_centrifugado_2_mean = []\n",
    "turbidez_centrifugado_2_max = []\n",
    "for lote in lotes:\n",
    "    cinetico = cineticos_centrifugacion[cineticos_centrifugacion['Lote'] == lote]\n",
    "    vol_centrifugado_1_min.append(cinetico['Volumen_centrifugado_1'].min())\n",
    "    vol_centrifugado_1_mean.append(cinetico['Volumen_centrifugado_1'].mean())\n",
    "    vol_centrifugado_1_max.append(cinetico['Volumen_centrifugado_1'].max())\n",
    "    vol_centrifugado_2_min.append(cinetico['Volumen_centrifugado_2'].min())\n",
    "    vol_centrifugado_2_mean.append(cinetico['Volumen_centrifugado_2'].mean())\n",
    "    vol_centrifugado_2_max.append(cinetico['Volumen_centrifugado_2'].max())\n",
    "    turbidez_centrifugado_1_min.append(cinetico['Turbidez_centrifugado_1'].min())\n",
    "    turbidez_centrifugado_1_mean.append(cinetico['Turbidez_centrifugado_1'].mean())\n",
    "    turbidez_centrifugado_1_max.append(cinetico['Turbidez_centrifugado_1'].max())\n",
    "    turbidez_centrifugado_2_min.append(cinetico['Turbidez_centrifugado_2'].min())\n",
    "    turbidez_centrifugado_2_mean.append(cinetico['Turbidez_centrifugado_2'].mean())\n",
    "    turbidez_centrifugado_2_max.append(cinetico['Turbidez_centrifugado_2'].max())\n",
    "#¬†Creamos un dataframe con los valores\n",
    "cineticos_centrifugacion = pd.DataFrame({'Lote': lotes, 'Volumen_centrifugado_1_min': vol_centrifugado_1_min, 'Volumen_centrifugado_1_mean': vol_centrifugado_1_mean, 'Volumen_centrifugado_1_max': vol_centrifugado_1_max, 'Volumen_centrifugado_2_min': vol_centrifugado_2_min, 'Volumen_centrifugado_2_mean': vol_centrifugado_2_mean, 'Volumen_centrifugado_2_max': vol_centrifugado_2_max, 'Turbidez_centrifugado_1_min': turbidez_centrifugado_1_min, 'Turbidez_centrifugado_1_mean': turbidez_centrifugado_1_mean, 'Turbidez_centrifugado_1_max': turbidez_centrifugado_1_max, 'Turbidez_centrifugado_2_min': turbidez_centrifugado_2_min, 'Turbidez_centrifugado_2_mean': turbidez_centrifugado_2_mean, 'Turbidez_centrifugado_2_max': turbidez_centrifugado_2_max})\n",
    "cineticos_centrifugacion = cineticos_centrifugacion.drop_duplicates(subset=['Lote'])\n",
    "print(\"El n√∫mero de filas y columnas de cineticos_centrifugacion es: \", cineticos_centrifugacion.shape)\n",
    "#¬†Nos guardamos el cineticos_centrifugacion\n",
    "cineticos_centrifugacion.to_csv('./processed_data/cineticos_centrifugacion.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de filas y columnas de movimientos es:  (5024, 7)\n",
      "El n√∫mero de filas y columnas de movimientos es:  (5024, 7)\n",
      "El n√∫mero de filas y columnas de movimientos es:  (4618, 7)\n",
      "El n√∫mero de filas y columnas de movimientos es:  (181, 2)\n"
     ]
    }
   ],
   "source": [
    "#Movimientos componentes.xlsx\n",
    "movimientos = pd.read_excel('data/Movimientos componentes.xlsx')\n",
    "print(\"El n√∫mero de filas y columnas de movimientos es: \", movimientos.shape)\n",
    "try:\n",
    "    movimientos['Lote'] = movimientos['Lote'].apply(lambda x: int(x))\n",
    "except:\n",
    "    #¬†Si no se puede pasar a int, es que hay un valor que no es un n√∫mero\n",
    "    # y por ende se tiene que eliminar\n",
    "    movimientos = movimientos[movimientos['Lote'] != 'Lote']\n",
    "print(\"El n√∫mero de filas y columnas de movimientos es: \", movimientos.shape)\n",
    "#¬†OFs\n",
    "of = pd.read_csv('./processed_data/of.csv')\n",
    "#¬†Nos quedamos con el lote y lo pasamos a int\n",
    "of = of[['Lote']]\n",
    "of['Lote'] = of['Lote'].apply(lambda x: int(x))\n",
    "#¬†Solo usamos los lotes que est√°n en movimientos\n",
    "movimientos = movimientos[movimientos['Lote'].isin(of['Lote'])]\n",
    "print(\"El n√∫mero de filas y columnas de movimientos es: \", movimientos.shape)\n",
    "# Para cada lote nos guardamos la columna Qty, que es un indicador de calidad del producto\n",
    "lotes = movimientos['Lote'].unique()\n",
    "qty = []\n",
    "for lote in lotes:\n",
    "    mov = movimientos[movimientos['Lote'] == lote]\n",
    "    qty.append(mov['Qty'].mean())\n",
    "#¬†Creamos un dataframe con los valores\n",
    "movimientos = pd.DataFrame({'Lote': lotes, 'Qty': qty})\n",
    "movimientos = movimientos.drop_duplicates(subset=['Lote'])\n",
    "print(\"El n√∫mero de filas y columnas de movimientos es: \", movimientos.shape)\n",
    "#¬†Nos guardamos el movimientos\n",
    "movimientos.to_csv('./processed_data/movimientos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bioreactor:  13171\n",
      "Bioreactor:  13172\n",
      "Bioreactor:  14618\n",
      "Bioreactor:  13169\n",
      "Bioreactor:  13170\n",
      "Bioreactor:  14614\n",
      "Bioreactor:  14615\n",
      "Bioreactor:  14616\n",
      "Bioreactor:  14617\n"
     ]
    }
   ],
   "source": [
    "# Ahora creamos una funci√≥n que nos permita hacer lo mismo para todos los bioreactores con diferentes ID\n",
    "def preprocesing_bioreactor(id_biorreactor):\n",
    "    biorreactor = pd.read_excel('data/Biorreactores/Biorreactor ' + str(id_biorreactor) + '.xlsx', sheet_name='Datos')\n",
    "    biorreactor = biorreactor.rename(columns={'DateTime': 'F_h_bio_in'})\n",
    "    biorreactor['F_h_bio_in'] = biorreactor['F_h_bio_in'].apply(lambda x: x[:-4])\n",
    "    biorreactor['F_h_bio_in'] = pd.to_datetime(biorreactor['F_h_bio_in'], format='%Y-%m-%d %H:%M:%S')\n",
    "    id_biorreactor = str(id_biorreactor)\n",
    "    biorreactor = biorreactor.rename(columns={id_biorreactor + '_FERM0101.Agitation_PV': 'Agitation_PV', id_biorreactor + '_FERM0101.Air_Sparge_PV': 'Air_Sparge_PV', id_biorreactor + '_FERM0101.Biocontainer_Pressure_PV': 'Pressure_PV', id_biorreactor + '_FERM0101.DO_1_PV': 'DO_1_PV', id_biorreactor + '_FERM0101.DO_2_PV': 'DO_2_PV', id_biorreactor + '_FERM0101.Gas_Overlay_PV': 'Gas_Overlay_PV', id_biorreactor + '_FERM0101.Load_Cell_Net_PV': 'Load_Cell_Net_PV', id_biorreactor + '_FERM0101.pH_1_PV': 'pH_1_PV', id_biorreactor + '_FERM0101.pH_2_PV': 'pH_2_PV'})\n",
    "    biorreactor = biorreactor.rename(columns={id_biorreactor + '_FERM0101.PUMP_1_PV': 'PUMP_1_PV', id_biorreactor + '_FERM0101.PUMP_2_PV': 'PUMP_2_PV', id_biorreactor + '_FERM0101.PUMP_1_TOTAL': 'PUMP_1_TOTAL', id_biorreactor + '_FERM0101.PUMP_2_TOTAL': 'PUMP_2_TOTAL', id_biorreactor + '_FERM0101.Single_Use_DO_PV': 'Single_Use_DO_PV', id_biorreactor + '_FERM0101.Single_Use_pH_PV': 'Single_Use_pH_PV', id_biorreactor + '_FERM0101.Temperatura_PV': 'Temperatura_PV'})\n",
    "    biorreactor['Agitation_PV'] = pd.to_numeric(biorreactor['Agitation_PV'], errors='coerce')\n",
    "    biorreactor['Agitation_PV'] = biorreactor['Agitation_PV'].astype(float)\n",
    "    biorreactor['Agitation_PV'] = biorreactor['Agitation_PV'].fillna(method='ffill')\n",
    "    biorreactor['Air_Sparge_PV'] = pd.to_numeric(biorreactor['Air_Sparge_PV'], errors='coerce')\n",
    "    biorreactor['Air_Sparge_PV'] = biorreactor['Air_Sparge_PV'].astype(float)\n",
    "    biorreactor['Air_Sparge_PV'] = biorreactor['Air_Sparge_PV'].fillna(method='ffill')\n",
    "    biorreactor['Pressure_PV'] = pd.to_numeric(biorreactor['Pressure_PV'], errors='coerce')\n",
    "    biorreactor['Pressure_PV'] = biorreactor['Pressure_PV'].astype(float)\n",
    "    biorreactor['Pressure_PV'] = biorreactor['Pressure_PV'].fillna(method='ffill')\n",
    "    biorreactor['DO_1_PV'] = pd.to_numeric(biorreactor['DO_1_PV'], errors='coerce')\n",
    "    biorreactor['DO_1_PV'] = biorreactor['DO_1_PV'].astype(float)\n",
    "    biorreactor['DO_1_PV'] = biorreactor['DO_1_PV'].fillna(method='ffill')\n",
    "    biorreactor['DO_2_PV'] = pd.to_numeric(biorreactor['DO_2_PV'], errors='coerce')\n",
    "    biorreactor['DO_2_PV'] = biorreactor['DO_2_PV'].astype(float)\n",
    "    biorreactor['DO_2_PV'] = biorreactor['DO_2_PV'].fillna(method='ffill')\n",
    "    biorreactor['Gas_Overlay_PV'] = pd.to_numeric(biorreactor['Gas_Overlay_PV'], errors='coerce')\n",
    "    biorreactor['Gas_Overlay_PV'] = biorreactor['Gas_Overlay_PV'].astype(float)\n",
    "    biorreactor['Gas_Overlay_PV'] = biorreactor['Gas_Overlay_PV'].fillna(method='ffill')\n",
    "    biorreactor['Load_Cell_Net_PV'] = pd.to_numeric(biorreactor['Load_Cell_Net_PV'], errors='coerce')\n",
    "    biorreactor['Load_Cell_Net_PV'] = biorreactor['Load_Cell_Net_PV'].astype(float)\n",
    "    biorreactor['Load_Cell_Net_PV'] = biorreactor['Load_Cell_Net_PV'].fillna(method='ffill')\n",
    "    biorreactor['pH_1_PV'] = pd.to_numeric(biorreactor['pH_1_PV'], errors='coerce')\n",
    "    biorreactor['pH_1_PV'] = biorreactor['pH_1_PV'].astype(float)\n",
    "    biorreactor['pH_1_PV'] = biorreactor['pH_1_PV'].fillna(method='ffill')\n",
    "    biorreactor['pH_2_PV'] = pd.to_numeric(biorreactor['pH_2_PV'], errors='coerce')\n",
    "    biorreactor['pH_2_PV'] = biorreactor['pH_2_PV'].astype(float)\n",
    "    biorreactor['pH_2_PV'] = biorreactor['pH_2_PV'].fillna(method='ffill')\n",
    "    biorreactor['PUMP_1_PV'] = pd.to_numeric(biorreactor['PUMP_1_PV'], errors='coerce')\n",
    "    biorreactor['PUMP_1_PV'] = biorreactor['PUMP_1_PV'].astype(float)\n",
    "    biorreactor['PUMP_1_PV'] = biorreactor['PUMP_1_PV'].fillna(method='ffill')\n",
    "    biorreactor['PUMP_2_PV'] = pd.to_numeric(biorreactor['PUMP_2_PV'], errors='coerce')\n",
    "    biorreactor['PUMP_2_PV'] = biorreactor['PUMP_2_PV'].astype(float)\n",
    "    biorreactor['PUMP_2_PV'] = biorreactor['PUMP_2_PV'].fillna(method='ffill')\n",
    "    biorreactor['PUMP_1_TOTAL'] = pd.to_numeric(biorreactor['PUMP_1_TOTAL'], errors='coerce')\n",
    "    biorreactor['PUMP_1_TOTAL'] = biorreactor['PUMP_1_TOTAL'].astype(float)\n",
    "    biorreactor['PUMP_1_TOTAL'] = biorreactor['PUMP_1_TOTAL'].fillna(method='ffill')\n",
    "    biorreactor['PUMP_2_TOTAL'] = pd.to_numeric(biorreactor['PUMP_2_TOTAL'], errors='coerce')\n",
    "    biorreactor['PUMP_2_TOTAL'] = biorreactor['PUMP_2_TOTAL'].astype(float)\n",
    "    biorreactor['PUMP_2_TOTAL'] = biorreactor['PUMP_2_TOTAL'].fillna(method='ffill')\n",
    "    biorreactor['Single_Use_DO_PV'] = pd.to_numeric(biorreactor['Single_Use_DO_PV'], errors='coerce')\n",
    "    biorreactor['Single_Use_DO_PV'] = biorreactor['Single_Use_DO_PV'].astype(float)\n",
    "    biorreactor['Single_Use_DO_PV'] = biorreactor['Single_Use_DO_PV'].fillna(method='ffill')\n",
    "    biorreactor['Single_Use_pH_PV'] = pd.to_numeric(biorreactor['Single_Use_pH_PV'], errors='coerce')\n",
    "    biorreactor['Single_Use_pH_PV'] = biorreactor['Single_Use_pH_PV'].astype(float)\n",
    "    biorreactor['Single_Use_pH_PV'] = biorreactor['Single_Use_pH_PV'].fillna(method='ffill')\n",
    "    biorreactor['Temperatura_PV'] = pd.to_numeric(biorreactor['Temperatura_PV'], errors='coerce')\n",
    "    biorreactor['Temperatura_PV'] = biorreactor['Temperatura_PV'].astype(float)\n",
    "    biorreactor['Temperatura_PV'] = biorreactor['Temperatura_PV'].fillna(method='ffill')\n",
    "    biorreactor['ID_biorreactor'] = id_biorreactor\n",
    "    biorreactor = biorreactor.sort_values(by=['ID_biorreactor'])\n",
    "    biorreactor['ID_biorreactor'] = biorreactor['ID_biorreactor'].astype(int)\n",
    "    #¬†Ordenamos por fecha\n",
    "    biorreactor = biorreactor.sort_values(by=['F_h_bio_in'])\n",
    "    biorreactor.to_csv('./processed_data/biorreactores/biorreactor_' + str(id_biorreactor) + '.csv', index=False)\n",
    "#¬†Con los IDs de los bioreactores √∫nicos, vamos a leerlos de data/Biorreactor xxxxx.xlsx\n",
    "bioreactores = [13171, 13172, 14618]\n",
    "for bioreactor in bioreactores:\n",
    "    print('Bioreactor: ', bioreactor)\n",
    "    preprocesing_bioreactor(bioreactor)\n",
    "#¬†Combinamos todos los bioreactores en un solo dataframe que llamaremos bioreactores_peque√±os\n",
    "bioreactores_peque√±os = pd.DataFrame()\n",
    "for bioreactor in bioreactores:\n",
    "    tmp = pd.read_csv('./processed_data/biorreactores/biorreactor_' + str(bioreactor) + '.csv')\n",
    "    bioreactores_peque√±os = pd.concat([bioreactores_peque√±os, tmp])\n",
    "bioreactores_peque√±os.to_csv('./processed_data/biorreactores/biorreactores_peque√±os.csv', index=False)\n",
    "#¬†Con los IDs de los bioreactores √∫nicos, vamos a leerlos de data/Biorreactor xxxxx.xlsx\n",
    "bioreactores = [13169, 13170, 14614, 14615, 14616, 14617]\n",
    "for bioreactor in bioreactores:\n",
    "    print('Bioreactor: ', bioreactor)\n",
    "    preprocesing_bioreactor(bioreactor)\n",
    "#¬†Combinamos todos los bioreactores en un solo dataframe que llamaremos bioreactores_peque√±os\n",
    "bioreactores_grandes = pd.DataFrame()\n",
    "for bioreactor in bioreactores:\n",
    "    tmp = pd.read_csv('./processed_data/biorreactores/biorreactor_' + str(bioreactor) + '.csv')\n",
    "    bioreactores_grandes = pd.concat([bioreactores_grandes, tmp])\n",
    "bioreactores_grandes.to_csv('./processed_data/biorreactores/bioreactores_grandes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centrifuga:  12912\n",
      "Centrifuga:  14246\n",
      "Centrifuga:  17825\n",
      "Shape:  (52413, 9)\n",
      "Shape after:  (52413, 9)\n",
      "Shape:  (52413, 9)\n",
      "Shape after:  (104826, 16)\n",
      "Shape:  (52413, 9)\n",
      "Shape after:  (157239, 23)\n"
     ]
    }
   ],
   "source": [
    "def preprocesing_centrifuga(id_centrifuga):\n",
    "    centrifuga = pd.read_excel('data/Centrifugadoras/Centr√≠fuga ' + str(id_centrifuga) + '.xlsx', sheet_name='Datos')\n",
    "    # Cambiamos el nombre de DateTime a Fecha\n",
    "    centrifuga = centrifuga.rename(columns={'DateTime': 'F_h_cen_cul'})\n",
    "    centrifuga['F_h_cen_cul'] = centrifuga['F_h_cen_cul'].apply(lambda x: x[:-4])\n",
    "    centrifuga['F_h_cen_cul'] = pd.to_datetime(centrifuga['F_h_cen_cul'], format='%Y-%m-%d %H:%M:%S')\n",
    "    #¬†Pasamos todas las columnas a float menos la fecha\n",
    "    columns = centrifuga.columns\n",
    "    for column in columns:\n",
    "        if column != 'F_h_cen_cul':\n",
    "            centrifuga[column] = pd.to_numeric(centrifuga[column], errors='coerce')\n",
    "            centrifuga[column] = centrifuga[column].astype(float)\n",
    "            #¬†Si hay alg√∫n valor NaN, lo cambiamos usando forward fill\n",
    "            centrifuga[column] = centrifuga[column].fillna(method='ffill')\n",
    "    #¬†Finalmente a√±adimos una columna con el ID de la centr√≠fuga\n",
    "    centrifuga['ID_centrifuga'] = id_centrifuga\n",
    "    #¬†Ordenamos por Fecha\n",
    "    centrifuga = centrifuga.sort_values(by=['F_h_cen_cul'])\n",
    "    centrifuga\n",
    "    #¬†Guardamos el dataframe en un csv\n",
    "    centrifuga.to_csv('./processed_data/centrifugadoras/centrifuga_' + str(id_centrifuga) + '.csv', index=False)\n",
    "\n",
    "centrifugadoras = [12912,14246,17825]\n",
    "for centrifuga in centrifugadoras:\n",
    "    print('Centrifuga: ', centrifuga)\n",
    "    preprocesing_centrifuga(centrifuga)\n",
    "\n",
    "#¬†Combinamos todos los bioreactores en un solo dataframe que llamaremos bioreactores_peque√±os\n",
    "centrifugadoras_cultivo = pd.DataFrame()\n",
    "for centrifuga in centrifugadoras:\n",
    "    tmp = pd.read_csv('./processed_data/centrifugadoras/centrifuga_' + str(centrifuga) + '.csv')\n",
    "    print(\"Shape: \", tmp.shape)\n",
    "    centrifugadoras_cultivo = pd.concat([centrifugadoras_cultivo, tmp])\n",
    "    print(\"Shape after: \", centrifugadoras_cultivo.shape)\n",
    "centrifugadoras_cultivo.to_csv('./processed_data/centrifugadoras/centrifugadoras.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_h_cen_tem_hum</th>\n",
       "      <th>temp_bio</th>\n",
       "      <th>hum_bio</th>\n",
       "      <th>temp_cen</th>\n",
       "      <th>hum_cen</th>\n",
       "      <th>temp_almacen</th>\n",
       "      <th>hum_almacen</th>\n",
       "      <th>temp_produccion</th>\n",
       "      <th>hum_produccion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-15 00:00:00</td>\n",
       "      <td>23.931585</td>\n",
       "      <td>34.801435</td>\n",
       "      <td>22.854169</td>\n",
       "      <td>35.223422</td>\n",
       "      <td>18.901909</td>\n",
       "      <td>35.290073</td>\n",
       "      <td>20.247395</td>\n",
       "      <td>48.842590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-15 01:00:00</td>\n",
       "      <td>23.747978</td>\n",
       "      <td>34.404315</td>\n",
       "      <td>21.562853</td>\n",
       "      <td>36.619001</td>\n",
       "      <td>18.786171</td>\n",
       "      <td>35.456451</td>\n",
       "      <td>20.247395</td>\n",
       "      <td>48.712383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-15 02:00:00</td>\n",
       "      <td>23.615734</td>\n",
       "      <td>33.789356</td>\n",
       "      <td>22.580972</td>\n",
       "      <td>33.759999</td>\n",
       "      <td>18.453837</td>\n",
       "      <td>35.040508</td>\n",
       "      <td>20.133463</td>\n",
       "      <td>48.571323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-15 03:00:00</td>\n",
       "      <td>19.906570</td>\n",
       "      <td>38.749275</td>\n",
       "      <td>19.631797</td>\n",
       "      <td>38.061402</td>\n",
       "      <td>18.422140</td>\n",
       "      <td>33.698639</td>\n",
       "      <td>20.133463</td>\n",
       "      <td>48.296440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-15 04:00:00</td>\n",
       "      <td>19.037770</td>\n",
       "      <td>39.895817</td>\n",
       "      <td>19.551820</td>\n",
       "      <td>37.560487</td>\n",
       "      <td>18.726911</td>\n",
       "      <td>32.628036</td>\n",
       "      <td>19.997829</td>\n",
       "      <td>48.166233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13099</th>\n",
       "      <td>2024-09-10 20:00:00</td>\n",
       "      <td>18.594929</td>\n",
       "      <td>71.293758</td>\n",
       "      <td>18.877224</td>\n",
       "      <td>64.958649</td>\n",
       "      <td>20.865883</td>\n",
       "      <td>46.839989</td>\n",
       "      <td>21.306482</td>\n",
       "      <td>45.888538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13100</th>\n",
       "      <td>2024-09-10 21:00:00</td>\n",
       "      <td>18.399609</td>\n",
       "      <td>72.166002</td>\n",
       "      <td>18.865017</td>\n",
       "      <td>65.335573</td>\n",
       "      <td>20.486107</td>\n",
       "      <td>46.724247</td>\n",
       "      <td>21.169041</td>\n",
       "      <td>43.729252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13101</th>\n",
       "      <td>2024-09-10 22:00:00</td>\n",
       "      <td>18.289743</td>\n",
       "      <td>71.672722</td>\n",
       "      <td>18.692587</td>\n",
       "      <td>68.999299</td>\n",
       "      <td>20.105803</td>\n",
       "      <td>46.185329</td>\n",
       "      <td>20.626505</td>\n",
       "      <td>43.327778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13102</th>\n",
       "      <td>2024-09-10 23:00:00</td>\n",
       "      <td>18.399609</td>\n",
       "      <td>71.721550</td>\n",
       "      <td>18.828394</td>\n",
       "      <td>73.986536</td>\n",
       "      <td>19.997826</td>\n",
       "      <td>46.062355</td>\n",
       "      <td>20.357046</td>\n",
       "      <td>44.282639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13103</th>\n",
       "      <td>2024-09-11 00:00:00</td>\n",
       "      <td>18.167669</td>\n",
       "      <td>72.234261</td>\n",
       "      <td>18.460646</td>\n",
       "      <td>70.110168</td>\n",
       "      <td>19.704857</td>\n",
       "      <td>45.530670</td>\n",
       "      <td>20.221413</td>\n",
       "      <td>44.951763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13104 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          F_h_cen_tem_hum   temp_bio    hum_bio   temp_cen    hum_cen  \\\n",
       "0     2023-03-15 00:00:00  23.931585  34.801435  22.854169  35.223422   \n",
       "1     2023-03-15 01:00:00  23.747978  34.404315  21.562853  36.619001   \n",
       "2     2023-03-15 02:00:00  23.615734  33.789356  22.580972  33.759999   \n",
       "3     2023-03-15 03:00:00  19.906570  38.749275  19.631797  38.061402   \n",
       "4     2023-03-15 04:00:00  19.037770  39.895817  19.551820  37.560487   \n",
       "...                   ...        ...        ...        ...        ...   \n",
       "13099 2024-09-10 20:00:00  18.594929  71.293758  18.877224  64.958649   \n",
       "13100 2024-09-10 21:00:00  18.399609  72.166002  18.865017  65.335573   \n",
       "13101 2024-09-10 22:00:00  18.289743  71.672722  18.692587  68.999299   \n",
       "13102 2024-09-10 23:00:00  18.399609  71.721550  18.828394  73.986536   \n",
       "13103 2024-09-11 00:00:00  18.167669  72.234261  18.460646  70.110168   \n",
       "\n",
       "       temp_almacen  hum_almacen  temp_produccion  hum_produccion  \n",
       "0         18.901909    35.290073        20.247395       48.842590  \n",
       "1         18.786171    35.456451        20.247395       48.712383  \n",
       "2         18.453837    35.040508        20.133463       48.571323  \n",
       "3         18.422140    33.698639        20.133463       48.296440  \n",
       "4         18.726911    32.628036        19.997829       48.166233  \n",
       "...             ...          ...              ...             ...  \n",
       "13099     20.865883    46.839989        21.306482       45.888538  \n",
       "13100     20.486107    46.724247        21.169041       43.729252  \n",
       "13101     20.105803    46.185329        20.626505       43.327778  \n",
       "13102     19.997826    46.062355        20.357046       44.282639  \n",
       "13103     19.704857    45.530670        20.221413       44.951763  \n",
       "\n",
       "[13104 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperatura_humedad = pd.read_excel('data/Temperaturas y humedades.xlsx', sheet_name='Datos')\n",
    "temperatura_humedad = temperatura_humedad.rename(columns={'DateTime': 'F_h_cen_tem_hum'})\n",
    "temperatura_humedad['F_h_cen_tem_hum'] = temperatura_humedad['F_h_cen_tem_hum'].apply(lambda x: x[:-4])\n",
    "temperatura_humedad['F_h_cen_tem_hum'] = pd.to_datetime(temperatura_humedad['F_h_cen_tem_hum'], format='%Y-%m-%d %H:%M:%S')\n",
    "columns = temperatura_humedad.columns\n",
    "for column in columns:\n",
    "    if column != 'F_h_cen_tem_hum':\n",
    "        temperatura_humedad[column] = pd.to_numeric(temperatura_humedad[column], errors='coerce')\n",
    "        temperatura_humedad[column] = temperatura_humedad[column].astype(float)\n",
    "        #¬†Si hay alg√∫n valor NaN, lo cambiamos usando forward fill\n",
    "        temperatura_humedad[column] = temperatura_humedad[column].fillna(method='ffill')\n",
    "#¬†Cambiamos el nombre de las columnas\n",
    "temperatura_humedad = temperatura_humedad.rename(columns={'06299_TI1302.PV': 'temp_bio','06299_MI1302.PV': 'hum_bio','06299_TI1402.PV': 'temp_cen','06299_MI1402.PV': 'hum_cen','07633_TI0601.PV': 'temp_almacen','07633_HI0101.PV': 'hum_almacen', '07781_TI1501.PV': 'temp_produccion','07781_MI1501.PV': 'hum_produccion'})\n",
    "temperatura_humedad.to_csv('./processed_data/temperatura_humedad.csv', index=False)\n",
    "temperatura_humedad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching Time üïí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aqui modificamos las filas de prein√≥culo e in√≥culo para que tengan en cuenta lo del lote parental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de filas y columnas de preinoculos es:  (157, 8)\n",
      "El n√∫mero de filas y columnas de inoculos es:  (157, 9)\n",
      "El n√∫mero de filas y columnas de cultivos es:  (150, 16)\n",
      "\n",
      "\n",
      "El n√∫mero de filas y columnas de preinoculos es:  (183, 8)\n",
      "El n√∫mero de filas y columnas de inoculos es:  (183, 9)\n",
      "El n√∫mero de filas y columnas de cultivos es:  (150, 16)\n"
     ]
    }
   ],
   "source": [
    "#¬†Empezamos leyendo preinoculos y lo macheamos con inoculo \n",
    "preinoculos = pd.read_csv('./processed_data/preinoculo.csv') # contiene 165 filas\n",
    "inoculos = pd.read_csv('./processed_data/inoculo.csv') # contiene 168 filas\n",
    "cultivos = pd.read_csv('./processed_data/cultivo.csv') # contiene 168 filas\n",
    "cultivos['Lote_parental'] = pd.to_numeric(cultivos['Lote_parental'], errors='coerce')\n",
    "cultivos['Lote_parental'] = cultivos['Lote_parental'].astype('Int64')\n",
    "print(\"El n√∫mero de filas y columnas de preinoculos es: \", preinoculos.shape)\n",
    "print(\"El n√∫mero de filas y columnas de inoculos es: \", inoculos.shape)\n",
    "print(\"El n√∫mero de filas y columnas de cultivos es: \", cultivos.shape)\n",
    "lotes_cultivo = cultivos['Lote'].unique() #¬†Obtenemos los lotes de cultivo\n",
    "for lote in lotes_cultivo:\n",
    "    tmp = cultivos[cultivos['Lote'] == lote]\n",
    "    if tmp['orden_encadenado'].values[0] == 2:\n",
    "        #¬†Creamos una nueva fila en preinoculo\n",
    "        tmp2 = preinoculos[preinoculos['Lote'] == tmp['Lote_parental'].values[0]]\n",
    "        tmp2['Lote'] = lote\n",
    "        preinoculos = pd.concat([preinoculos, tmp2])\n",
    "        #¬†Ahora en inoculo\n",
    "        tmp2 = inoculos[inoculos['Lote'] == tmp['Lote_parental'].values[0]]\n",
    "        tmp2['Lote'] = lote\n",
    "        inoculos = pd.concat([inoculos, tmp2])\n",
    "    # EN caso de que sea una orden encadenado 3, miramos el lote parental del lote parental\n",
    "    if tmp['orden_encadenado'].values[0] == 3:\n",
    "        tmp2 = cultivos[cultivos['Lote'] == tmp['Lote_parental'].values[0]]\n",
    "        tmp3 = preinoculos[preinoculos['Lote'] == tmp2['Lote_parental'].values[0]]\n",
    "        tmp3['Lote'] = lote\n",
    "        preinoculos = pd.concat([preinoculos, tmp3])\n",
    "        #¬†Ahora en inoculo\n",
    "        tmp3 = inoculos[inoculos['Lote'] == tmp2['Lote_parental'].values[0]]\n",
    "        tmp3['Lote'] = lote\n",
    "        inoculos = pd.concat([inoculos, tmp3])\n",
    "preinoculos = preinoculos.drop_duplicates(subset=['Lote'])\n",
    "inoculos = inoculos.drop_duplicates(subset=['Lote'])\n",
    "cultivos = cultivos.drop_duplicates(subset=['Lote'])\n",
    "print(\"\\n\")\n",
    "print(\"El n√∫mero de filas y columnas de preinoculos es: \", preinoculos.shape)\n",
    "print(\"El n√∫mero de filas y columnas de inoculos es: \", inoculos.shape)\n",
    "print(\"El n√∫mero de filas y columnas de cultivos es: \", cultivos.shape)\n",
    "preinoculos.to_csv('./processed_data/preinoculo.csv', index=False)\n",
    "inoculos.to_csv('./processed_data/inoculo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de filas y columnas de preinoculos es:  (183, 8)\n",
      "El n√∫mero de filas y columnas de inoculos es:  (183, 9)\n",
      "El n√∫mero de filas y columnas de cultivos es:  (55, 16)\n",
      "\n",
      "\n",
      "El n√∫mero de filas y columnas de preinoculos es:  (205, 8)\n",
      "El n√∫mero de filas y columnas de inoculos es:  (205, 9)\n",
      "El n√∫mero de filas y columnas de cultivos es:  (55, 16)\n"
     ]
    }
   ],
   "source": [
    "#¬†Empezamos leyendo preinoculos y lo macheamos con inoculo \n",
    "preinoculos = pd.read_csv('./processed_data/preinoculo.csv') # contiene 165 filas\n",
    "inoculos = pd.read_csv('./processed_data/inoculo.csv') # contiene 168 filas\n",
    "cultivos = pd.read_csv('./processed_data/cultivo_test.csv') # contiene 168 filas\n",
    "cultivos['Lote_parental'] = pd.to_numeric(cultivos['Lote_parental'], errors='coerce')\n",
    "cultivos['Lote_parental'] = cultivos['Lote_parental'].astype('Int64')\n",
    "print(\"El n√∫mero de filas y columnas de preinoculos es: \", preinoculos.shape)\n",
    "print(\"El n√∫mero de filas y columnas de inoculos es: \", inoculos.shape)\n",
    "print(\"El n√∫mero de filas y columnas de cultivos es: \", cultivos.shape)\n",
    "lotes_cultivo = cultivos['Lote'].unique() #¬†Obtenemos los lotes de cultivo\n",
    "for lote in lotes_cultivo:\n",
    "    tmp = cultivos[cultivos['Lote'] == lote]\n",
    "    if tmp['orden_encadenado'].values[0] == 2:\n",
    "        #¬†Creamos una nueva fila en preinoculo\n",
    "        tmp2 = preinoculos[preinoculos['Lote'] == tmp['Lote_parental'].values[0]]\n",
    "        tmp2['Lote'] = lote\n",
    "        preinoculos = pd.concat([preinoculos, tmp2])\n",
    "        #¬†Ahora en inoculo\n",
    "        tmp2 = inoculos[inoculos['Lote'] == tmp['Lote_parental'].values[0]]\n",
    "        tmp2['Lote'] = lote\n",
    "        inoculos = pd.concat([inoculos, tmp2])\n",
    "    # EN caso de que sea una orden encadenado 3, miramos el lote parental del lote parental\n",
    "    if tmp['orden_encadenado'].values[0] == 3:\n",
    "        tmp2 = cultivos[cultivos['Lote'] == tmp['Lote_parental'].values[0]]\n",
    "        tmp3 = preinoculos[preinoculos['Lote'] == tmp2['Lote_parental'].values[0]]\n",
    "        tmp3['Lote'] = lote\n",
    "        preinoculos = pd.concat([preinoculos, tmp3])\n",
    "        #¬†Ahora en inoculo\n",
    "        tmp3 = inoculos[inoculos['Lote'] == tmp2['Lote_parental'].values[0]]\n",
    "        tmp3['Lote'] = lote\n",
    "        inoculos = pd.concat([inoculos, tmp3])\n",
    "preinoculos = preinoculos.drop_duplicates(subset=['Lote'])\n",
    "inoculos = inoculos.drop_duplicates(subset=['Lote'])\n",
    "cultivos = cultivos.drop_duplicates(subset=['Lote'])\n",
    "print(\"\\n\")\n",
    "print(\"El n√∫mero de filas y columnas de preinoculos es: \", preinoculos.shape)\n",
    "print(\"El n√∫mero de filas y columnas de inoculos es: \", inoculos.shape)\n",
    "print(\"El n√∫mero de filas y columnas de cultivos es: \", cultivos.shape)\n",
    "preinoculos.to_csv('./processed_data/preinoculo.csv', index=False)\n",
    "inoculos.to_csv('./processed_data/inoculo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aqui a√±adimos al cultivo los centrifuagados y los biorreactores, adem√°s de los cin√©ticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de filas y columnas de cultivos es:  (150, 127)\n",
      "El n√∫mero de filas y columnas de cultivos es:  (150, 136)\n",
      "El n√∫mero de filas y columnas de cultivos es:  (150, 148)\n",
      "El n√∫mero de filas y columnas de cultivos es:  (150, 149)\n"
     ]
    }
   ],
   "source": [
    "centrifugadoras = pd.read_csv('./processed_data/centrifugadoras/centrifugadoras.csv')\n",
    "\n",
    "#¬†Ahora hacemos lo mismo para el cultivo y las centrifugadoras\n",
    "cultivos = pd.read_csv('./processed_data/cultivo.csv')\n",
    "#¬†Creamos nuevas columnas en cultivo que ser√° todas las que hay en centrifugadoras, menos F_h_cen_cul y ID_centrifuga\n",
    "columnas_nuevas = centrifugadoras.columns.drop(['F_h_cen_cul', 'ID_centrifuga'])\n",
    "for columna in columnas_nuevas:\n",
    "    cultivos[columna + '_min'] = np.nan\n",
    "    cultivos[columna + '_max'] = np.nan\n",
    "    cultivos[columna + '_mean'] = np.nan\n",
    "for i in range(0, len(cultivos)):\n",
    "    fecha_inicio = cultivos.loc[i, 'F_h_init_cul']\n",
    "    fecha_fin = cultivos.loc[i, 'F_h_end_cul']\n",
    "    if pd.isnull(fecha_inicio) or pd.isnull(fecha_fin):\n",
    "        continue\n",
    "    else:\n",
    "        #¬†Ahora buscamos en el csv de centrifugadoras el cultivo y creamos un nuevo dataframe con tantas columnas como el csv de centrifugadoras\n",
    "        tmp = centrifugadoras[(centrifugadoras['F_h_cen_cul'] >= fecha_inicio) & (centrifugadoras['F_h_cen_cul'] <= fecha_fin)]\n",
    "        # Rellenamos las columnas de cultivo\n",
    "        if len(tmp) > 0:\n",
    "            for columna in columnas_nuevas:\n",
    "                cultivos.loc[i, columna + '_min'] = tmp[columna].min()\n",
    "                cultivos.loc[i, columna + '_max'] = tmp[columna].max()\n",
    "                cultivos.loc[i, columna + '_mean'] = tmp[columna].mean()\n",
    "\n",
    "bioreactores_grandes = pd.read_csv('./processed_data/biorreactores/bioreactores_grandes.csv')\n",
    "\n",
    "columnas_nuevas = bioreactores_grandes.columns.drop(['F_h_bio_in', 'ID_biorreactor'])\n",
    "for columna in columnas_nuevas:\n",
    "    cultivos[columna + '_min'] = np.nan\n",
    "    cultivos[columna + '_max'] = np.nan\n",
    "    cultivos[columna + '_mean'] = np.nan\n",
    "for i in range(0, len(cultivos)):\n",
    "    fecha_inicio = cultivos.loc[i, 'F_h_init_cul']\n",
    "    fecha_fin = cultivos.loc[i, 'F_h_end_cul']\n",
    "    if pd.isnull(fecha_inicio) or pd.isnull(fecha_fin):\n",
    "        continue\n",
    "    else:\n",
    "        #¬†Ahora buscamos en el csv de centrifugadoras el cultivo y creamos un nuevo dataframe con tantas columnas como el csv de centrifugadoras\n",
    "        tmp = bioreactores_grandes[(bioreactores_grandes['F_h_bio_in'] >= fecha_inicio) & (bioreactores_grandes['F_h_bio_in'] <= fecha_fin)]\n",
    "        # Rellenamos las columnas de cultivo\n",
    "        if len(tmp) > 0:\n",
    "            for columna in columnas_nuevas:\n",
    "                cultivos.loc[i, columna + '_min'] = tmp[columna].min()\n",
    "                cultivos.loc[i, columna + '_max'] = tmp[columna].max()\n",
    "                cultivos.loc[i, columna + '_mean'] = tmp[columna].mean()\n",
    "print(\"El n√∫mero de filas y columnas de cultivos es: \", cultivos.shape)\n",
    "cineticos_cultivos = pd.read_csv('./processed_data/cineticos_cultivos.csv')\n",
    "lotes = cultivos['Lote'].unique()\n",
    "cineticos_cultivos = cineticos_cultivos[cineticos_cultivos['Lote'].isin(lotes)]\n",
    "#¬†Hacemos el merge\n",
    "cultivos = pd.merge(cultivos, cineticos_cultivos, on='Lote', how='left')\n",
    "print(\"El n√∫mero de filas y columnas de cultivos es: \", cultivos.shape)\n",
    "cineticos_centrifugacion = pd.read_csv('./processed_data/cineticos_centrifugacion.csv')\n",
    "lotes = cultivos['Lote'].unique()\n",
    "cineticos_centrifugacion = cineticos_centrifugacion[cineticos_centrifugacion['Lote'].isin(lotes)]\n",
    "#¬†Hacemos el merge\n",
    "cultivos = pd.merge(cultivos, cineticos_centrifugacion, on='Lote', how='left')\n",
    "print(\"El n√∫mero de filas y columnas de cultivos es: \", cultivos.shape)\n",
    "movimientos = pd.read_csv('./processed_data/movimientos.csv')\n",
    "lotes = cultivos['Lote'].unique()\n",
    "movimientos = movimientos[movimientos['Lote'].isin(lotes)]\n",
    "#¬†Hacemos el merge\n",
    "cultivos = pd.merge(cultivos, movimientos, on='Lote', how='left')\n",
    "print(\"El n√∫mero de filas y columnas de cultivos es: \", cultivos.shape)\n",
    "cultivos.to_csv('./processed_data/train/cultivos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de filas y columnas de cultivos es:  (55, 127)\n",
      "El n√∫mero de filas y columnas de cultivos es:  (55, 136)\n",
      "El n√∫mero de filas y columnas de cultivos es:  (55, 148)\n",
      "El n√∫mero de filas y columnas de cultivos es:  (55, 149)\n"
     ]
    }
   ],
   "source": [
    "centrifugadoras = pd.read_csv('./processed_data/centrifugadoras/centrifugadoras.csv')\n",
    "\n",
    "#¬†Ahora hacemos lo mismo para el cultivo y las centrifugadoras\n",
    "cultivos = pd.read_csv('./processed_data/cultivo_test.csv')\n",
    "#¬†Creamos nuevas columnas en cultivo que ser√° todas las que hay en centrifugadoras, menos F_h_cen_cul y ID_centrifuga\n",
    "columnas_nuevas = centrifugadoras.columns.drop(['F_h_cen_cul', 'ID_centrifuga'])\n",
    "for columna in columnas_nuevas:\n",
    "    cultivos[columna + '_min'] = np.nan\n",
    "    cultivos[columna + '_max'] = np.nan\n",
    "    cultivos[columna + '_mean'] = np.nan\n",
    "for i in range(0, len(cultivos)):\n",
    "    fecha_inicio = cultivos.loc[i, 'F_h_init_cul']\n",
    "    fecha_fin = cultivos.loc[i, 'F_h_end_cul']\n",
    "    if pd.isnull(fecha_inicio) or pd.isnull(fecha_fin):\n",
    "        continue\n",
    "    else:\n",
    "        #¬†Ahora buscamos en el csv de centrifugadoras el cultivo y creamos un nuevo dataframe con tantas columnas como el csv de centrifugadoras\n",
    "        tmp = centrifugadoras[(centrifugadoras['F_h_cen_cul'] >= fecha_inicio) & (centrifugadoras['F_h_cen_cul'] <= fecha_fin)]\n",
    "        # Rellenamos las columnas de cultivo\n",
    "        if len(tmp) > 0:\n",
    "            for columna in columnas_nuevas:\n",
    "                cultivos.loc[i, columna + '_min'] = tmp[columna].min()\n",
    "                cultivos.loc[i, columna + '_max'] = tmp[columna].max()\n",
    "                cultivos.loc[i, columna + '_mean'] = tmp[columna].mean()\n",
    "\n",
    "bioreactores_grandes = pd.read_csv('./processed_data/biorreactores/bioreactores_grandes.csv')\n",
    "\n",
    "columnas_nuevas = bioreactores_grandes.columns.drop(['F_h_bio_in', 'ID_biorreactor'])\n",
    "for columna in columnas_nuevas:\n",
    "    cultivos[columna + '_min'] = np.nan\n",
    "    cultivos[columna + '_max'] = np.nan\n",
    "    cultivos[columna + '_mean'] = np.nan\n",
    "for i in range(0, len(cultivos)):\n",
    "    fecha_inicio = cultivos.loc[i, 'F_h_init_cul']\n",
    "    fecha_fin = cultivos.loc[i, 'F_h_end_cul']\n",
    "    if pd.isnull(fecha_inicio) or pd.isnull(fecha_fin):\n",
    "        continue\n",
    "    else:\n",
    "        #¬†Ahora buscamos en el csv de centrifugadoras el cultivo y creamos un nuevo dataframe con tantas columnas como el csv de centrifugadoras\n",
    "        tmp = bioreactores_grandes[(bioreactores_grandes['F_h_bio_in'] >= fecha_inicio) & (bioreactores_grandes['F_h_bio_in'] <= fecha_fin)]\n",
    "        # Rellenamos las columnas de cultivo\n",
    "        if len(tmp) > 0:\n",
    "            for columna in columnas_nuevas:\n",
    "                cultivos.loc[i, columna + '_min'] = tmp[columna].min()\n",
    "                cultivos.loc[i, columna + '_max'] = tmp[columna].max()\n",
    "                cultivos.loc[i, columna + '_mean'] = tmp[columna].mean()\n",
    "print(\"El n√∫mero de filas y columnas de cultivos es: \", cultivos.shape)\n",
    "cineticos_cultivos = pd.read_csv('./processed_data/cineticos_cultivos.csv')\n",
    "lotes = cultivos['Lote'].unique()\n",
    "cineticos_cultivos = cineticos_cultivos[cineticos_cultivos['Lote'].isin(lotes)]\n",
    "#¬†Hacemos el merge\n",
    "cultivos = pd.merge(cultivos, cineticos_cultivos, on='Lote', how='left')\n",
    "print(\"El n√∫mero de filas y columnas de cultivos es: \", cultivos.shape)\n",
    "cineticos_centrifugacion = pd.read_csv('./processed_data/cineticos_centrifugacion.csv')\n",
    "lotes = cultivos['Lote'].unique()\n",
    "cineticos_centrifugacion = cineticos_centrifugacion[cineticos_centrifugacion['Lote'].isin(lotes)]\n",
    "#¬†Hacemos el merge\n",
    "cultivos = pd.merge(cultivos, cineticos_centrifugacion, on='Lote', how='left')\n",
    "print(\"El n√∫mero de filas y columnas de cultivos es: \", cultivos.shape)\n",
    "movimientos = pd.read_csv('./processed_data/movimientos.csv')\n",
    "lotes = cultivos['Lote'].unique()\n",
    "movimientos = movimientos[movimientos['Lote'].isin(lotes)]\n",
    "#¬†Hacemos el merge\n",
    "cultivos = pd.merge(cultivos, movimientos, on='Lote', how='left')\n",
    "print(\"El n√∫mero de filas y columnas de cultivos es: \", cultivos.shape)\n",
    "cultivos.to_csv('./processed_data/test/cultivos.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aqui vamos a hacer los biorreactores de inoculo y su cin√©tico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de filas y columnas de inoculos es:  (205, 57)\n",
      "El n√∫mero de filas y columnas de inoculos es:  (205, 63)\n"
     ]
    }
   ],
   "source": [
    "inoculos = pd.read_csv('./processed_data/inoculo.csv')\n",
    "bioreactores_peque√±os = pd.read_csv('./processed_data/biorreactores/biorreactores_peque√±os.csv')\n",
    "\n",
    "columnas_nuevas = bioreactores_peque√±os.columns.drop(['F_h_bio_in', 'ID_biorreactor'])\n",
    "for columna in columnas_nuevas:\n",
    "    inoculos[columna + '_min'] = np.nan\n",
    "    inoculos[columna + '_max'] = np.nan\n",
    "    inoculos[columna + '_mean'] = np.nan\n",
    "for i in range(0, len(inoculos)): #F_h_init_in\n",
    "    fecha_inicio = inoculos.loc[i, 'F_h_init_in']\n",
    "    fecha_fin = inoculos.loc[i, 'F_h_end_in']\n",
    "    if pd.isnull(fecha_inicio) or pd.isnull(fecha_fin):\n",
    "        continue\n",
    "    else:\n",
    "        #¬†Ahora buscamos en el csv de centrifugadoras el cultivo y creamos un nuevo dataframe con tantas columnas como el csv de centrifugadoras\n",
    "        tmp = bioreactores_peque√±os[(bioreactores_peque√±os['F_h_bio_in'] >= fecha_inicio) & (bioreactores_peque√±os['F_h_bio_in'] <= fecha_fin)]\n",
    "        # Rellenamos las columnas de cultivo\n",
    "        if len(tmp) > 0:\n",
    "            for columna in columnas_nuevas:\n",
    "                inoculos.loc[i, columna + '_min'] = tmp[columna].min()\n",
    "                inoculos.loc[i, columna + '_max'] = tmp[columna].max()\n",
    "                inoculos.loc[i, columna + '_mean'] = tmp[columna].mean()\n",
    "print(\"El n√∫mero de filas y columnas de inoculos es: \", inoculos.shape)\n",
    "cineticos_inoculos = pd.read_csv('./processed_data/cineticos_inoculos.csv')\n",
    "lotes = inoculos['Lote'].unique()\n",
    "cineticos_inoculos = cineticos_inoculos[cineticos_inoculos['Lote'].isin(lotes)]\n",
    "#¬†Hacemos el merge\n",
    "inoculos = pd.merge(inoculos, cineticos_inoculos, on='Lote', how='left')\n",
    "print(\"El n√∫mero de filas y columnas de inoculos es: \", inoculos.shape)\n",
    "inoculos.to_csv('./processed_data/inoculo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de filas y columnas de preinoculos es:  (205, 8)\n",
      "El n√∫mero de filas y columnas de inoculos es:  (205, 63)\n",
      "El n√∫mero de filas y columnas de cultivos es:  (150, 149)\n",
      "El n√∫mero de filas y columnas de preinoculos_cultivo es:  (150, 8)\n",
      "El n√∫mero de filas y columnas de inoculos_cultivo es:  (150, 63)\n",
      "El n√∫mero de filas y columnas de preinoculos_cultivo es:  (150, 70)\n",
      "El n√∫mero de filas y columnas de preinoculos_cultivo es:  (150, 218)\n"
     ]
    }
   ],
   "source": [
    "preinoculos = pd.read_csv('./processed_data/preinoculo.csv')\n",
    "inoculos = pd.read_csv('./processed_data/inoculo.csv')\n",
    "cultivos = pd.read_csv('./processed_data/train/cultivos.csv')\n",
    "print(\"El n√∫mero de filas y columnas de preinoculos es: \", preinoculos.shape)\n",
    "print(\"El n√∫mero de filas y columnas de inoculos es: \", inoculos.shape)\n",
    "print(\"El n√∫mero de filas y columnas de cultivos es: \", cultivos.shape)\n",
    "\n",
    "preinoculos['Lote'] = preinoculos['Lote'].astype('Int64')\n",
    "inoculos['Lote'] = inoculos['Lote'].astype('Int64')\n",
    "cultivos['Lote'] = cultivos['Lote'].astype('Int64')\n",
    "preinoculos = preinoculos.sort_values(by=['Lote'])\n",
    "inoculos = inoculos.sort_values(by=['Lote'])\n",
    "cultivos = cultivos.sort_values(by=['Lote'])\n",
    "lotes_cultivo = cultivos['Lote'].unique()\n",
    "preinoculos_cultivo = preinoculos[preinoculos['Lote'].isin(lotes_cultivo)]\n",
    "inoculos_cultivo = inoculos[inoculos['Lote'].isin(lotes_cultivo)]\n",
    "\n",
    "print(\"El n√∫mero de filas y columnas de preinoculos_cultivo es: \", preinoculos_cultivo.shape)\n",
    "print(\"El n√∫mero de filas y columnas de inoculos_cultivo es: \", inoculos_cultivo.shape)\n",
    "#¬†Hacemos un merge de preinoculos_cultivo con inoculos_cultivo\n",
    "preinoculos_cultivo = pd.merge(preinoculos_cultivo, inoculos_cultivo, on='Lote', how='left')\n",
    "print(\"El n√∫mero de filas y columnas de preinoculos_cultivo es: \", preinoculos_cultivo.shape)\n",
    "#¬†Hacemos un merge de preinoculos_cultivo con cultivos\n",
    "preinoculos_cultivo = pd.merge(preinoculos_cultivo, cultivos, on='Lote', how='left')\n",
    "print(\"El n√∫mero de filas y columnas de preinoculos_cultivo es: \", preinoculos_cultivo.shape)\n",
    "preinoculos_cultivo.to_csv('./processed_data/train/train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de filas y columnas de preinoculos es:  (205, 8)\n",
      "El n√∫mero de filas y columnas de inoculos es:  (205, 63)\n",
      "El n√∫mero de filas y columnas de cultivos es:  (55, 149)\n",
      "El n√∫mero de filas y columnas de preinoculos_cultivo es:  (55, 8)\n",
      "El n√∫mero de filas y columnas de inoculos_cultivo es:  (55, 63)\n",
      "El n√∫mero de filas y columnas de preinoculos_cultivo es:  (55, 70)\n",
      "El n√∫mero de filas y columnas de preinoculos_cultivo es:  (55, 218)\n"
     ]
    }
   ],
   "source": [
    "preinoculos = pd.read_csv('./processed_data/preinoculo.csv')\n",
    "inoculos = pd.read_csv('./processed_data/inoculo.csv')\n",
    "cultivos = pd.read_csv('./processed_data/test/cultivos.csv')\n",
    "print(\"El n√∫mero de filas y columnas de preinoculos es: \", preinoculos.shape)\n",
    "print(\"El n√∫mero de filas y columnas de inoculos es: \", inoculos.shape)\n",
    "print(\"El n√∫mero de filas y columnas de cultivos es: \", cultivos.shape)\n",
    "\n",
    "preinoculos['Lote'] = preinoculos['Lote'].astype('Int64')\n",
    "inoculos['Lote'] = inoculos['Lote'].astype('Int64')\n",
    "cultivos['Lote'] = cultivos['Lote'].astype('Int64')\n",
    "preinoculos = preinoculos.sort_values(by=['Lote'])\n",
    "inoculos = inoculos.sort_values(by=['Lote'])\n",
    "cultivos = cultivos.sort_values(by=['Lote'])\n",
    "lotes_cultivo = cultivos['Lote'].unique()\n",
    "preinoculos_cultivo = preinoculos[preinoculos['Lote'].isin(lotes_cultivo)]\n",
    "inoculos_cultivo = inoculos[inoculos['Lote'].isin(lotes_cultivo)]\n",
    "\n",
    "print(\"El n√∫mero de filas y columnas de preinoculos_cultivo es: \", preinoculos_cultivo.shape)\n",
    "print(\"El n√∫mero de filas y columnas de inoculos_cultivo es: \", inoculos_cultivo.shape)\n",
    "#¬†Hacemos un merge de preinoculos_cultivo con inoculos_cultivo\n",
    "preinoculos_cultivo = pd.merge(preinoculos_cultivo, inoculos_cultivo, on='Lote', how='left')\n",
    "print(\"El n√∫mero de filas y columnas de preinoculos_cultivo es: \", preinoculos_cultivo.shape)\n",
    "#¬†Hacemos un merge de preinoculos_cultivo con cultivos\n",
    "preinoculos_cultivo = pd.merge(preinoculos_cultivo, cultivos, on='Lote', how='left')\n",
    "print(\"El n√∫mero de filas y columnas de preinoculos_cultivo es: \", preinoculos_cultivo.shape)\n",
    "preinoculos_cultivo.to_csv('./processed_data/test/test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigaci√≥n del train üïµüèæ\n",
    "\n",
    "Generamos un informe de los datos de Entrenamiento para ver que tipo de datos tenemos y si hay valores nulos y que correlacion tienen los datos con la variable objetivo. Adem√°s de eliminar aquellas columnas que no aporten informaci√≥n relevante (como puede ser la fecha). Tambi√©n aprovechamos y pasamos todos los datos a float64 para que no haya problemas a la hora de entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = pd.read_csv('./processed_data/train/train_data.csv')\n",
    "# We store in a txt the columns and the type of the columns\n",
    "with open('./processed_data/train/columns.txt', 'w') as f:\n",
    "    for col in train_data.columns:\n",
    "        f.write(f'{col} - {train_data[col].dtype}\\n')\n",
    "#¬†Drop all the object columns except those that starts with 'Durac'\n",
    "import re\n",
    "pattern = re.compile('Durac')\n",
    "columns_to_drop = [col for col in train_data.columns if train_data[col].dtype == 'object' and not pattern.match(col)]\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "#¬†Now we parse the object columns to seconds, because they are in datetime format\n",
    "for col in train_data.columns:\n",
    "    if train_data[col].dtype == 'object':\n",
    "        train_data[col] = pd.to_timedelta(train_data[col]).dt.total_seconds()\n",
    "#¬†We store the columns in a txt\n",
    "with open('./processed_data/train/columns_clean.txt', 'a') as f:\n",
    "    for col in train_data.columns:\n",
    "        f.write(f'{col} - {train_data[col].dtype}\\n')\n",
    "\n",
    "#¬†For each column we are going to store in a txt the mean, std, min, max and the number of NaN values, also the correlation with product 1\n",
    "corr = train_data.corr()['Producto 1'].sort_values(ascending=False)\n",
    "#¬†Sort the columns by correlation\n",
    "corr = corr[corr.index]\n",
    "#¬†We store the correlation in a txt\n",
    "with open('./processed_data/train/stats.txt', 'w') as f:\n",
    "    for col in corr.index:\n",
    "        f.write(f'{col}\\n')\n",
    "        f.write(f'Mean: {train_data[col].mean()}\\n')\n",
    "        f.write(f'Std: {train_data[col].std()}\\n')\n",
    "        f.write(f'Min: {train_data[col].min()}\\n')\n",
    "        f.write(f'Max: {train_data[col].max()}\\n')\n",
    "        f.write(f'NaN values: {train_data[col].isna().sum()}\\n')\n",
    "        f.write(f'Correlation with Producto 1: {corr[col]}\\n\\n')\n",
    "\n",
    "\n",
    "# Load the data\n",
    "test_data = pd.read_csv('./processed_data/test/test_data.csv')\n",
    "# We store in a txt the columns and the type of the columns\n",
    "with open('./processed_data/test/columns.txt', 'w') as f:\n",
    "    for col in test_data.columns:\n",
    "        f.write(f'{col} - {test_data[col].dtype}\\n')\n",
    "#¬†Drop all the object columns except those that starts with 'Durac'\n",
    "import re\n",
    "pattern = re.compile('Durac')\n",
    "columns_to_drop = [col for col in test_data.columns if test_data[col].dtype == 'object' and not pattern.match(col)]\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)\n",
    "#¬†Now we parse the object columns to seconds, because they are in datetime format\n",
    "for col in test_data.columns:\n",
    "    if test_data[col].dtype == 'object':\n",
    "        test_data[col] = pd.to_timedelta(test_data[col]).dt.total_seconds()\n",
    "#¬†We store the columns in a txt\n",
    "with open('./processed_data/test/columns_clean.txt', 'a') as f:\n",
    "    for col in test_data.columns:\n",
    "        f.write(f'{col} - {test_data[col].dtype}\\n')\n",
    "\n",
    "#¬†For each column we are going to store in a txt the mean, std, min, max and the number of NaN values, also the correlation with product 1\n",
    "#corr = train_data.corr()['Producto 1'].sort_values(ascending=False)\n",
    "#¬†Sort the columns by correlation\n",
    "corr = corr[corr.index]\n",
    "#¬†We store the correlation in a txt\n",
    "with open('./processed_data/test/stats.txt', 'w') as f:\n",
    "    for col in corr.index:\n",
    "        f.write(f'{col}\\n')\n",
    "        f.write(f'Mean: {test_data[col].mean()}\\n')\n",
    "        f.write(f'Std: {test_data[col].std()}\\n')\n",
    "        f.write(f'Min: {test_data[col].min()}\\n')\n",
    "        f.write(f'Max: {test_data[col].max()}\\n')\n",
    "        f.write(f'NaN values: {test_data[col].isna().sum()}\\n')\n",
    "        f.write(f'Correlation with Producto 1: {corr[col]}\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#¬†Store the data\n",
    "train_data.to_csv('./processed_data/train/train_data_clean.csv', index=False)\n",
    "test_data.to_csv('./processed_data/test/test_data_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
