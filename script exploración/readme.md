# PredicciÃ³n de ConcentraciÃ³n de AntÃ­genos en ProducciÃ³n de Vacunas

## ğŸ¯ DescripciÃ³n del Proyecto
Este proyecto, desarrollado para el UniversityHack 2024, se centra en la optimizaciÃ³n de la producciÃ³n de antÃ­genos para el desarrollo de vacunas. Implementamos un ensemble de modelos de machine learning para predecir la concentraciÃ³n final del antÃ­geno, considerando mÃºltiples variables del proceso productivo.

## ğŸ“ Estructura del Repositorio

```
â”œâ”€â”€ script exploraciÃ³n/
â”‚   â”œâ”€â”€ data/                    # Datos iniciales
â”‚   â”œâ”€â”€ processed_data/          # Datos procesados
â”‚   â”œâ”€â”€ data_cleaning_and_analysis.ipynb  # Notebook de preprocesamiento
â”‚   â””â”€â”€ data_cleaning_and_analysis.py     # Script de preprocesamiento
â”‚
â””â”€â”€ script predicciÃ³n/
    â”œâ”€â”€ tmp/                     # Modelos optimizados
    â”œâ”€â”€ log/                     # Registros de entrenamiento
    â”œâ”€â”€ dataloader.py           # Carga y escalado de datos
    â”œâ”€â”€ model.py               # DefiniciÃ³n de modelos
    â”œâ”€â”€ pipeline.py            # Pipeline de entrenamiento
    â””â”€â”€ main.py               # Script principal
```

## ğŸ“Š Rendimiento de los Modelos

| Modelo | RMSE | DesviaciÃ³n EstÃ¡ndar | Emisiones CO2 (g) | Tiempo (s) |
|--------|------|---------------------|-------------------|------------|
| Ensemble | 249.53 | Â±23.47 | 0.00203 | 5.58 |
| CatBoost | 252.97 | Â±35.58 | 0.00090 | 2.58 |
| Random Forest | 257.83 | Â±26.23 | 0.00057 | 1.51 |
| XGBoost | 261.74 | Â±23.70 | 0.00152 | 4.30 |
| LightGBM | 264.67 | Â±22.55 | 0.00079 | 2.11 |
| Gradient Boosting | 263.52 | Â±17.92 | 0.00056 | 1.68 |

## ğŸš€ CaracterÃ­sticas Principales

- **Ensemble Avanzado**: ImplementaciÃ³n de voting con pesos optimizados
- **Explicabilidad**: AnÃ¡lisis detallado mediante SHAP
- **Sostenibilidad**: MonitorizaciÃ³n de emisiones CO2 con CodeCarbon
- **ValidaciÃ³n Robusta**: Sistema de validaciÃ³n cruzada 5-fold
- **Preprocesamiento**: Manejo especÃ­fico de valores nulos y escalado de datos

## ğŸ› ï¸ Requisitos

```bash
pip install pandas numpy scikit-learn xgboost lightgbm catboost shap codecarbon
```

## ğŸ“ˆ Resultados Destacados

- ğŸ† El ensemble superÃ³ consistentemente a los modelos individuales
- ğŸ“Š DistribuciÃ³n de pesos optimizada (CatBoost: 6.0, RandomForest: 3.5)
- ğŸŒ± Emisiones totales inferiores a 0.003g CO2
- ğŸ” IdentificaciÃ³n de variables clave mediante anÃ¡lisis SHAP

## ğŸ¤ Contribuciones
Desarrollado por el equipo HAL9000 para UniversityHack 2024.

## ğŸ“ Licencia
Este proyecto estÃ¡ bajo la licencia MIT.